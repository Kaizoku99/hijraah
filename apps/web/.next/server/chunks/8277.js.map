{"version":3,"file":"8277.js","mappings":"icACA,4BACA,kCACA,6BACA,kCACA,UACA,eACA,OAA8B,uBAAkC,CAChE,EAYA,KACA,KACA,gBACA,iBACA,2BACA,eACA,CAAC,EACD,UAlBA,aACA,+CACA,kBACA,kBAHA,IAGA,GACA,OAA6B,kDAA4F,EAEzH,SACA,EACA,IAAoD,eAAkB,SAAa,EAUnF,GAGA,MAA4B,EAAQ,KAAyB,EAC7D,QACA,EAFmC,OAEnC,CACA,2BACA,GACA,gCAEA,cACA,YACA,sCACA,eACA,CAAK,CACL,CAQA,qBACA,eACA,MAEA,cACA,KAEA,EACA,CACA,gBACA,yCACA,CACA,kBACA,eACA,wEACA,KAEA,kEACA,CACA,oBACA,eACA,wEACA,KAGA,OADA,oDAEA,CACA,4BAEA,OADA,iEAEA,CACA,0CACA,OAEA,oDADA,OACA,EACA,CACA,EAGA,QAIA,kBACA,GACA,YACA,CACA,aACA,sBACA,OAAe,oBAEf,+BACA,cACA,qBACA,CAAe,qBAEf,CAAa,mBACb,CACA,gBACA,mBACA,CACA,SACA,mBACA,CACA,OACA,8BACA,CACA,QACA,2BAGA,OAFA,KACA,oBACA,CACA,CACA,OACA,oBACA,CACA,QACA,kBACA,CACA,OACA,uBAEA,EAGA,cACA,wCACA,MACA,4CAAoD,EAAE,GAEtD,4BAEA,OADA,MAEA,SACA,QAEA,SACA,YAEA,SACA,eAEA,SACA,iBAEA,SACA,kBAEA,SACA,4CAAsD,EAAE,EAExD,CACA,CAGA,uBACA,IACA,wCACA,CAAI,SACJ,MAAW,EAAM,wBACjB,yCAMA,OALA,YACA,aACA,kJAGA,4BACA,CACA,OACA,CACA,EA4QA,GACA,cACA,aACA,OACA,OA7QA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,EAiQA,+CACA,CAAO,CACP,cACA,OAnQA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,MA2PA,+CACA,CACA,CAAK,CACL,eACA,OACA,OA/PA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,EAiOA,+CACA,CAAO,CACP,cACA,OAnOA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA,EA+MA,+CACA,CACA,CAAK,CACL,aACA,OACA,OAnNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA,YAAY;AACZ;;AAEA;AACA;AACA;AACA;AACA;AACA,UAAU;AACV,EA8KA,+CACA,CAAO,CACP,cACA,OA/KA;;;;;;;;;;;CAWA,CAqKA,+CACA,CACA,CAAK,CACL,mBACA,OACA,OAzKA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,EA6JA,+CACA,CAAO,CACP,cACA,OA/JA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA,EAuJA,+CACA,CACA,CACA,CAAG,CACH,aACA,aACA,OACA,OA3JA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA,EA6IA,+CACA,CAAO,CACP,cACA,OA/IA;AACA;AACA;;AAEA;;AAEA;AACA,MAyIA,+CACA,CACA,CAAK,CACL,eACA,OACA,OA7IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,WAAW;AACX;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT,EA4GA,+CACA,CAAO,CACP,cACA,OA9GA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,EAyFA,+CACA,CACA,CACA,CACA,EACA,GACA,OA5FA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA,MAuEA,+CACA,EAGA,aACA,eACA,qBAGA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA,WAAW;AACX,EAGA,KACA,KACA,qBACA,wBACA,sBACA,CAAC,EAID,IAEA,KAFA,MAIA,CADA,gBAFA,IAGA,EAJA,MAUA,sBACA,eACA,+EAAmF,EAAU,GAC7F,0BACA,CACA,EACA,YACA,gCACA,eAEA,IACA,qBAAoC,QAAQ,uDAAG,OAAU,EACzD,CADyD,EACzD,MACA,oCAA8C,aAAoB,GAIlE,MADA,CADA,gBACA,YACA,qBACA,CAAI,SACJ,6CAAqD,EAAM,EAC3D,CACA,EACA,mBACA,iBACA,wBACA,oBACA,kBACA,YAOA,OANA,oBACA,SACA,gCACA,oBACA,qBACA,iBAAwC,UAA2B,EACnE,cACA,EACA,eACA,4BACA,oBACA,kBACA,YAIA,OAHA,oBACA,SACA,oBACA,cACA,EAGA,iBACA,KACA,OACA,2BAGA,MACA,cACA,UACA,8BACA,EACA,iBACA,IAQA,EARA,mBACA,EACA,CACA,sBACA,gBACA,CACA,GASA,OANA,cACA,IACA,QACA,OAEA,CAAG,EACH,CACA,cACA,wBACA,CACA,EACA,kBAOA,GANA,gBACA,aACA,cACA,oBACA,6BAEA,qBACA,cACA,wBACA,UACA,EACA,CACA,CACA,QACA,EACA,KACA,EACA,WACA,QACA,YACA,QACA,0BACA,kBACA,aACA,GAIA,QACA,QACA,IACA,OACA,QACA,aACA,UACA,iBACA,8BACA,GACA,eACA,uBACA,4BACA,2CACA,6CACA,8CACA,qFACA,kCACA,wBACA,kBACA,CAAK,SACL,gCACA,uCACM,2BACN,+BAEA,CAqCA,mBACA,WACA,IACA,qCACA,eAAc,kBAA8B,qBAC5C,IACA,4BAEA,OADA,2BAEA,EAAM,OACN,GACA,eAEA,CACA,EAuBA,iCAIA,EAHA,QACA,wCAGA,mBACA,MACA,wBACA,SAFA,CAKA,eACA,sCAEA,qCAEA,GADA,sCACA,aACA,KAEA,CACA,QACA,EACA,0BACA,+BACA,6CACA,EASA,uBACA,gCACA,oDACA,EAaA,kCACA,qBACA,8BACA,OACA,uBAAwE,uBAAuC,qBAC/G,yCACA,0DAAgG,yCAChG,EACA,gEACA,EAQA,iBACA,WACA,MACA,mBACA,sBACA,kBACA,GACA,WACA,QACA,YACA,QACA,0BACA,gBACA,CAAW,CACX,CAAS,cACT,CAAO,EACP,SACA,CACA,OACA,gBACA,cACA,CACA,EASA,0BACA,kBACA,IACA,4CACA,yBACA,iDACA,gBACA,iDACA,KACS,YACT,kCACA,IAAiB,EAAM,yBACvB;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA,OAEA,iBACA,CAAS,CACT,qCACA,CAAQ,SACR,4CACA,CAIA,QACA,EACA,UACA,yBAUA,0BACA,kCACA,eACA,EAIA,aACA,SACA,mEACA,WACA,YAAkB,KAAQ,IAC1B,yCAEA,QACA,CACA,sBAIA,eACA,OACA,gBACA,kBACA,kBACA,sBACA,KACA,gCACA,OACA,IACA,qDACA,CACA,CAAK,CACL,CAmBA,wBACA,WACA,YACA,mBACA,YACA,YAAkB,WAAyB,qBAC3C,KACA,OACA,WACA,QACA,YACA,QACA,0BACA,mBACA,CAEA,CACA,UACA,2BACA,kBACA,oBACA,4BACA,cACA,UACA,EACA,gCACA,IACA,QAEA,EAAS,EAST,IARA,yCACA,iBACA,QAIA,OAHA,KACA,uBAEA,GACA,CAAS,IAET,mBAEA,kBADA,yCAEA,wBACA,QACA,UAEA,GACa,KACb,UACA,gBAEA,OADA,iBACA,OACA,UACA,QAIA,OAHA,KACA,uBAEA,GACA,CAAe,CACf,GAGA,GADA,iBACA,iBACA,QACA,UAEA,GACa,IACb,QACA,SAEA,kCACA,gBAGA,eACA,sBAAyC,MAA2B,CAEpE,CACA,CACA,UACA,UAIA,OAHA,aACA,wBAEA,CACA,UACA,QACA,YACA,QACA,WACA,CACA,CAAO,CACP,wBACA,+BACA,kBACA,4BACA,cACA,UACA,EACA,uCACA,IACA,OAEA,EAAS,EAST,OACA,uBARA,CADA,wCACA,iBACA,QAIA,OAHA,KACA,uBAEA,GACA,CAAS,KAGT,aACA,CACA,CAAO,CACP,uBACA,uBACA,UACA,eAEA,2CACA,EACA,EACA,EACA,IACA,OAEA,CAAS,EACT,CACA,EACA,CAiBA,0BACA,WACA,OACA,YACA,mBACA,YACA,YAAkB,WAAyB,qBAC3C,KACA,OACA,WACA,QACA,YACA,QACA,0BACA,mBACA,CAEA,CACA,UACA,aACA,kBACA,kBAEA,KADA,IACA,WACA,oBACA,4BACA,cACA,UACA,EACA,kCACA,MACA,YAGA,EAAS,EACT,QACA,8CACA,IACA,uBAEA,yBACA,QAIA,OAHA,KACA,uBAEA,GACA,CAAS,IACT,qBACA,QAIA,OAHA,KACA,uBAEA,GACA,CAAS,IAGT,IADA,CADA,mBACA,GAEA,mBAEA,kBACA,CAFA,wCAEA,mCACA,QACA,UAEA,GACa,KACb,UACA,gBACA,2BACA,qBACA,QACA,UAEA,GACa,IAQb,GAPA,mBACA,QAIA,OAHA,KACA,uBAEA,GACA,CAAa,KACb,EACA,SAEA,kCACA,gBAGA,eACA,sBAAgD,MAA2B,CAE3E,CACA,CACA,cAIA,OAHA,aACA,wBAEA,CACA,YACA,QACA,wBACA,QACA,WACA,CACA,CAAO,CACP,wBACA,iBACA,kBACA,kBAEA,KADA,IACA,WACA,4BACA,cACA,UACA,EACA,yCACA,MACA,MAGA,EAAS,EAET,OACA,uBAFA,wCAGA,aACA,CACA,CAAO,CACP,uBACA,uBACA,UACA,eAEA,2CACA,EACA,EACA,EACA,IACA,OAEA,CAAS,EACT,CACA,EAAK,CAEL,EAGA,kBAIA,eACA,OACA,gBACA,kBACA,kBACA,sBACA,KACA,cACO,CACP,gCACA,oCACA,sCACK,CACL,CAmBA,wBACA,WACA,YACA,mBACA,+BACA,kBACA,YACA,IAAkB,mBAAyB,qBAC3C,KACA,OACA,WACA,QACA,YACA,QACA,0BACA,mBACA,CAEA,CACA,wBACA,UACA,EACA,iCACA,IACA,OAEA,OACA,kBACA,UAIA,OAHA,aACA,wBAEA,CACA,UACA,QACA,YACA,QACA,yBACA,CACA,CAAO,CACP,wBACA,+BACA,kBAOA,OACA,uBAPA,QACA,EACA,wCACA,IACA,SAIA,aACA,CACA,CAAO,CACP,uBACA,uBACA,UACA,eAEA,QACA,EACA,EACA,IACA,OAEA,CACA,EAAK,CAkBL,0BACA,WACA,YACA,mBACA,iBACA,kBACA,kBAEA,KADA,IACA,WACA,YACA,YAAkB,WAAyB,qBAC3C,KACA,OACA,WACA,QACA,YACA,QACA,0BACA,mBACA,CAEA,CACA,wBACA,UACA,EACA,mCACA,MACA,WAEA,OACA,UAIA,OAHA,aACA,wBAEA,CACA,UACA,QACA,wBACA,QACA,yBACA,CACA,CAAO,CACP,wBACA,iBACA,kBACA,kBAEA,KADA,IACA,WAOA,OACA,uBAPA,QACA,EACA,0CACA,MACA,QAIA,aACA,CACA,CAAO,CACP,uBACA,uBACA,UACA,eAEA,QACA,EACA,EACA,IACA,OAEA,CACA,EAAK,CAeL,0BACA,WACA,YACA,mBACA,YACA,YAAkB,WAAyB,qBAC3C,KACA,OACA,WACA,QACA,YACA,QACA,0BACA,mBACA,CAEA,CACA,iBACA,oBACA,cACA,EACA,iCACA,IACA,aAEA,OAIA,OAHA,aACA,wBAEA,CACA,UACA,QACA,YACA,QACA,yBACA,CACA,CAAO,CACP,wBACA,iBACA,EACA,wCACA,IACA,KAEA,eACA,MACA,OACA,YACA,gBACA,CACA,CAAO,CACP,uBAEA,SACA,eAEA,QACA,EACA,EACA,CAPA,EAOA,CACA,OAEA,CACA,EAAK,CA0BL,8BACA,WACA,YACA,mBACA,YACA,+CAEA,+BACA,kBACA,UACA,oBAEA,GADA,gCACA,CACA,sBACA,MACA,MACA,EACA,uCACA,IACA,OACA,kBACA,OACA,UACA,QACA,cACA,QACA,SACA,CACA,CACA,cACA,EACA,uCACA,IACA,OAEA,iBACA,UACA,OACA,aACA,QACA,YACA,QACA,yBACA,CACA,CAAO,CACP,wBACA,YACA,+CAEA,+BACA,wBACA,gCAGA,CACA,uBAFA,qBAGA,aACA,EAQA,CACA,uBAPA,QACA,EACA,8CACA,IACA,SAIA,aACA,CACA,CAAO,CACP,uBACA,YACA,+CAGA,SADA,yBACA,WACA,eACA,uBACA,SACA,EACA,EACA,IACA,OAEA,CACA,EAAK,CAEL,aCxnDa,4BAA4B,kCAAsC,6BAAiC,kCAAsC,EAAmR,GAAnR,SAAc,sBAAsB,uBAAuB,GAAE,CAA+N,GAAK,gBAAgB,EAAE,UAA5E,CAA1K,YAAe,8EAAf,SAAe,UAA6F,kDAAkD,EAAE,WAAU,IAAe,eAAe,SAAS,EAAqC,GAAoB;AAC7d;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA,wBAAwB,KAAK;AAC7B;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,uBAAuB;AACvB;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,eAAe;AAC/C;AACA;AACA,iCAAiC,eAAe;AAChD;AACA;AACA,kCAAkC,eAAe;AACjD;AACA;AACA;AACA;AACA;;AAEA,QAAQ;AACR;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA,uBAAuB;AACvB;AACA;;AAEA;AACA,EAAE,QAAY,MAAM,OAAO,UAAW,gBAAe,yGAAyG,qBAAqB,kEAAsE,EAAE,2EAA2E,eAAe,uBAAuB,uCAA2C,EAAE,GAAG,SAAS,wBAAwB,6CAAiD,EAAE,GAAG,mCAAmC,UAAU,oBAAqB,wBAAwB,0BAA2B,2BAA8B,6CAAgD,EAAE,IAAI,aAAiC,mBAApB,eAAoB,iCAAqD,qBAAqB,4DAA4D,0DAA2D,8CAA6C,iBAAiB,GAAG,GAAG,6BAA6B,SAAS,2BAA2B,+DAA+D,gCAAgC,GAAG,aAAa,6BAA6B,0BAA0B,yFAAyF,yCAAyC,gCAAgC,0BAA0B,6BAA6B,YAAY,IAAI,4DAA6D,sBAAsB,8CAA8C,kCAAkC,0DAA0D,YAAY,KAAK,MAAM,kCAAkC,0GAA2G,qFAAqF,+BAA+B,0BAA0B,8GAA8G,YAAY,WAAW,MAAM,oCAAoC,aAAa,qBAAoB,uCAAwC,SAAS,uCAAuC,0BAA0B,wHAA4H,OAAO,4EAA4E,WAAW,SAAS,YAAY,WAAW,MAAM,yBAAyB,QAAQ,gCAAgC,EAAE,WAAW","sources":["webpack://@hijraah/web/../../node_modules/.pnpm/@upstash+ratelimit@2.0.5_@upstash+redis@1.35.0/node_modules/@upstash/ratelimit/dist/index.js","webpack://@hijraah/web/../../node_modules/.pnpm/@upstash+core-analytics@0.0.10/node_modules/@upstash/core-analytics/dist/index.js"],"sourcesContent":["\"use strict\";\nvar __defProp = Object.defineProperty;\nvar __getOwnPropDesc = Object.getOwnPropertyDescriptor;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __hasOwnProp = Object.prototype.hasOwnProperty;\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\nvar __copyProps = (to, from, except, desc) => {\n  if (from && typeof from === \"object\" || typeof from === \"function\") {\n    for (let key of __getOwnPropNames(from))\n      if (!__hasOwnProp.call(to, key) && key !== except)\n        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n  }\n  return to;\n};\nvar __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\n\n// src/index.ts\nvar src_exports = {};\n__export(src_exports, {\n  Analytics: () => Analytics,\n  IpDenyList: () => ip_deny_list_exports,\n  MultiRegionRatelimit: () => MultiRegionRatelimit,\n  Ratelimit: () => RegionRatelimit\n});\nmodule.exports = __toCommonJS(src_exports);\n\n// src/analytics.ts\nvar import_core_analytics = require(\"@upstash/core-analytics\");\nvar Analytics = class {\n  analytics;\n  table = \"events\";\n  constructor(config) {\n    this.analytics = new import_core_analytics.Analytics({\n      // @ts-expect-error we need to fix the types in core-analytics, it should only require the methods it needs, not the whole sdk\n      redis: config.redis,\n      window: \"1h\",\n      prefix: config.prefix ?? \"@upstash/ratelimit\",\n      retention: \"90d\"\n    });\n  }\n  /**\n   * Try to extract the geo information from the request\n   *\n   * This handles Vercel's `req.geo` and  and Cloudflare's `request.cf` properties\n   * @param req\n   * @returns\n   */\n  extractGeo(req) {\n    if (req.geo !== void 0) {\n      return req.geo;\n    }\n    if (req.cf !== void 0) {\n      return req.cf;\n    }\n    return {};\n  }\n  async record(event) {\n    await this.analytics.ingest(this.table, event);\n  }\n  async series(filter, cutoff) {\n    const timestampCount = Math.min(\n      (this.analytics.getBucket(Date.now()) - this.analytics.getBucket(cutoff)) / (60 * 60 * 1e3),\n      256\n    );\n    return this.analytics.aggregateBucketsWithPipeline(this.table, filter, timestampCount);\n  }\n  async getUsage(cutoff = 0) {\n    const timestampCount = Math.min(\n      (this.analytics.getBucket(Date.now()) - this.analytics.getBucket(cutoff)) / (60 * 60 * 1e3),\n      256\n    );\n    const records = await this.analytics.getAllowedBlocked(this.table, timestampCount);\n    return records;\n  }\n  async getUsageOverTime(timestampCount, groupby) {\n    const result = await this.analytics.aggregateBucketsWithPipeline(this.table, groupby, timestampCount);\n    return result;\n  }\n  async getMostAllowedBlocked(timestampCount, getTop, checkAtMost) {\n    getTop = getTop ?? 5;\n    const timestamp = void 0;\n    return this.analytics.getMostAllowedBlocked(this.table, timestampCount, getTop, timestamp, checkAtMost);\n  }\n};\n\n// src/cache.ts\nvar Cache = class {\n  /**\n   * Stores identifier -> reset (in milliseconds)\n   */\n  cache;\n  constructor(cache) {\n    this.cache = cache;\n  }\n  isBlocked(identifier) {\n    if (!this.cache.has(identifier)) {\n      return { blocked: false, reset: 0 };\n    }\n    const reset = this.cache.get(identifier);\n    if (reset < Date.now()) {\n      this.cache.delete(identifier);\n      return { blocked: false, reset: 0 };\n    }\n    return { blocked: true, reset };\n  }\n  blockUntil(identifier, reset) {\n    this.cache.set(identifier, reset);\n  }\n  set(key, value) {\n    this.cache.set(key, value);\n  }\n  get(key) {\n    return this.cache.get(key) || null;\n  }\n  incr(key) {\n    let value = this.cache.get(key) ?? 0;\n    value += 1;\n    this.cache.set(key, value);\n    return value;\n  }\n  pop(key) {\n    this.cache.delete(key);\n  }\n  empty() {\n    this.cache.clear();\n  }\n  size() {\n    return this.cache.size;\n  }\n};\n\n// src/duration.ts\nfunction ms(d) {\n  const match = d.match(/^(\\d+)\\s?(ms|s|m|h|d)$/);\n  if (!match) {\n    throw new Error(`Unable to parse window size: ${d}`);\n  }\n  const time = Number.parseInt(match[1]);\n  const unit = match[2];\n  switch (unit) {\n    case \"ms\": {\n      return time;\n    }\n    case \"s\": {\n      return time * 1e3;\n    }\n    case \"m\": {\n      return time * 1e3 * 60;\n    }\n    case \"h\": {\n      return time * 1e3 * 60 * 60;\n    }\n    case \"d\": {\n      return time * 1e3 * 60 * 60 * 24;\n    }\n    default: {\n      throw new Error(`Unable to parse window size: ${d}`);\n    }\n  }\n}\n\n// src/hash.ts\nvar safeEval = async (ctx, script, keys, args) => {\n  try {\n    return await ctx.redis.evalsha(script.hash, keys, args);\n  } catch (error) {\n    if (`${error}`.includes(\"NOSCRIPT\")) {\n      const hash = await ctx.redis.scriptLoad(script.script);\n      if (hash !== script.hash) {\n        console.warn(\n          \"Upstash Ratelimit: Expected hash and the hash received from Redis are different. Ratelimit will work as usual but performance will be reduced.\"\n        );\n      }\n      return await ctx.redis.evalsha(hash, keys, args);\n    }\n    throw error;\n  }\n};\n\n// src/lua-scripts/single.ts\nvar fixedWindowLimitScript = `\n  local key           = KEYS[1]\n  local window        = ARGV[1]\n  local incrementBy   = ARGV[2] -- increment rate per request at a given value, default is 1\n\n  local r = redis.call(\"INCRBY\", key, incrementBy)\n  if r == tonumber(incrementBy) then\n  -- The first time this key is set, the value will be equal to incrementBy.\n  -- So we only need the expire command once\n  redis.call(\"PEXPIRE\", key, window)\n  end\n\n  return r\n`;\nvar fixedWindowRemainingTokensScript = `\n      local key = KEYS[1]\n      local tokens = 0\n\n      local value = redis.call('GET', key)\n      if value then\n          tokens = value\n      end\n      return tokens\n    `;\nvar slidingWindowLimitScript = `\n  local currentKey  = KEYS[1]           -- identifier including prefixes\n  local previousKey = KEYS[2]           -- key of the previous bucket\n  local tokens      = tonumber(ARGV[1]) -- tokens per window\n  local now         = ARGV[2]           -- current timestamp in milliseconds\n  local window      = ARGV[3]           -- interval in milliseconds\n  local incrementBy = ARGV[4]           -- increment rate per request at a given value, default is 1\n\n  local requestsInCurrentWindow = redis.call(\"GET\", currentKey)\n  if requestsInCurrentWindow == false then\n    requestsInCurrentWindow = 0\n  end\n\n  local requestsInPreviousWindow = redis.call(\"GET\", previousKey)\n  if requestsInPreviousWindow == false then\n    requestsInPreviousWindow = 0\n  end\n  local percentageInCurrent = ( now % window ) / window\n  -- weighted requests to consider from the previous window\n  requestsInPreviousWindow = math.floor(( 1 - percentageInCurrent ) * requestsInPreviousWindow)\n  if requestsInPreviousWindow + requestsInCurrentWindow >= tokens then\n    return -1\n  end\n\n  local newValue = redis.call(\"INCRBY\", currentKey, incrementBy)\n  if newValue == tonumber(incrementBy) then\n    -- The first time this key is set, the value will be equal to incrementBy.\n    -- So we only need the expire command once\n    redis.call(\"PEXPIRE\", currentKey, window * 2 + 1000) -- Enough time to overlap with a new window + 1 second\n  end\n  return tokens - ( newValue + requestsInPreviousWindow )\n`;\nvar slidingWindowRemainingTokensScript = `\n  local currentKey  = KEYS[1]           -- identifier including prefixes\n  local previousKey = KEYS[2]           -- key of the previous bucket\n  local now         = ARGV[1]           -- current timestamp in milliseconds\n  local window      = ARGV[2]           -- interval in milliseconds\n\n  local requestsInCurrentWindow = redis.call(\"GET\", currentKey)\n  if requestsInCurrentWindow == false then\n    requestsInCurrentWindow = 0\n  end\n\n  local requestsInPreviousWindow = redis.call(\"GET\", previousKey)\n  if requestsInPreviousWindow == false then\n    requestsInPreviousWindow = 0\n  end\n\n  local percentageInCurrent = ( now % window ) / window\n  -- weighted requests to consider from the previous window\n  requestsInPreviousWindow = math.floor(( 1 - percentageInCurrent ) * requestsInPreviousWindow)\n\n  return requestsInPreviousWindow + requestsInCurrentWindow\n`;\nvar tokenBucketLimitScript = `\n  local key         = KEYS[1]           -- identifier including prefixes\n  local maxTokens   = tonumber(ARGV[1]) -- maximum number of tokens\n  local interval    = tonumber(ARGV[2]) -- size of the window in milliseconds\n  local refillRate  = tonumber(ARGV[3]) -- how many tokens are refilled after each interval\n  local now         = tonumber(ARGV[4]) -- current timestamp in milliseconds\n  local incrementBy = tonumber(ARGV[5]) -- how many tokens to consume, default is 1\n        \n  local bucket = redis.call(\"HMGET\", key, \"refilledAt\", \"tokens\")\n        \n  local refilledAt\n  local tokens\n\n  if bucket[1] == false then\n    refilledAt = now\n    tokens = maxTokens\n  else\n    refilledAt = tonumber(bucket[1])\n    tokens = tonumber(bucket[2])\n  end\n        \n  if now >= refilledAt + interval then\n    local numRefills = math.floor((now - refilledAt) / interval)\n    tokens = math.min(maxTokens, tokens + numRefills * refillRate)\n\n    refilledAt = refilledAt + numRefills * interval\n  end\n\n  if tokens == 0 then\n    return {-1, refilledAt + interval}\n  end\n\n  local remaining = tokens - incrementBy\n  local expireAt = math.ceil(((maxTokens - remaining) / refillRate)) * interval\n        \n  redis.call(\"HSET\", key, \"refilledAt\", refilledAt, \"tokens\", remaining)\n  redis.call(\"PEXPIRE\", key, expireAt)\n  return {remaining, refilledAt + interval}\n`;\nvar tokenBucketIdentifierNotFound = -1;\nvar tokenBucketRemainingTokensScript = `\n  local key         = KEYS[1]\n  local maxTokens   = tonumber(ARGV[1])\n        \n  local bucket = redis.call(\"HMGET\", key, \"refilledAt\", \"tokens\")\n\n  if bucket[1] == false then\n    return {maxTokens, ${tokenBucketIdentifierNotFound}}\n  end\n        \n  return {tonumber(bucket[2]), tonumber(bucket[1])}\n`;\nvar cachedFixedWindowLimitScript = `\n  local key     = KEYS[1]\n  local window  = ARGV[1]\n  local incrementBy   = ARGV[2] -- increment rate per request at a given value, default is 1\n\n  local r = redis.call(\"INCRBY\", key, incrementBy)\n  if r == incrementBy then\n  -- The first time this key is set, the value will be equal to incrementBy.\n  -- So we only need the expire command once\n  redis.call(\"PEXPIRE\", key, window)\n  end\n      \n  return r\n`;\nvar cachedFixedWindowRemainingTokenScript = `\n  local key = KEYS[1]\n  local tokens = 0\n\n  local value = redis.call('GET', key)\n  if value then\n      tokens = value\n  end\n  return tokens\n`;\n\n// src/lua-scripts/multi.ts\nvar fixedWindowLimitScript2 = `\n\tlocal key           = KEYS[1]\n\tlocal id            = ARGV[1]\n\tlocal window        = ARGV[2]\n\tlocal incrementBy   = tonumber(ARGV[3])\n\n\tredis.call(\"HSET\", key, id, incrementBy)\n\tlocal fields = redis.call(\"HGETALL\", key)\n\tif #fields == 2 and tonumber(fields[2])==incrementBy then\n\t-- The first time this key is set, and the value will be equal to incrementBy.\n\t-- So we only need the expire command once\n\t  redis.call(\"PEXPIRE\", key, window)\n\tend\n\n\treturn fields\n`;\nvar fixedWindowRemainingTokensScript2 = `\n      local key = KEYS[1]\n      local tokens = 0\n\n      local fields = redis.call(\"HGETALL\", key)\n\n      return fields\n    `;\nvar slidingWindowLimitScript2 = `\n\tlocal currentKey    = KEYS[1]           -- identifier including prefixes\n\tlocal previousKey   = KEYS[2]           -- key of the previous bucket\n\tlocal tokens        = tonumber(ARGV[1]) -- tokens per window\n\tlocal now           = ARGV[2]           -- current timestamp in milliseconds\n\tlocal window        = ARGV[3]           -- interval in milliseconds\n\tlocal requestId     = ARGV[4]           -- uuid for this request\n\tlocal incrementBy   = tonumber(ARGV[5]) -- custom rate, default is  1\n\n\tlocal currentFields = redis.call(\"HGETALL\", currentKey)\n\tlocal requestsInCurrentWindow = 0\n\tfor i = 2, #currentFields, 2 do\n\trequestsInCurrentWindow = requestsInCurrentWindow + tonumber(currentFields[i])\n\tend\n\n\tlocal previousFields = redis.call(\"HGETALL\", previousKey)\n\tlocal requestsInPreviousWindow = 0\n\tfor i = 2, #previousFields, 2 do\n\trequestsInPreviousWindow = requestsInPreviousWindow + tonumber(previousFields[i])\n\tend\n\n\tlocal percentageInCurrent = ( now % window) / window\n\tif requestsInPreviousWindow * (1 - percentageInCurrent ) + requestsInCurrentWindow >= tokens then\n\t  return {currentFields, previousFields, false}\n\tend\n\n\tredis.call(\"HSET\", currentKey, requestId, incrementBy)\n\n\tif requestsInCurrentWindow == 0 then \n\t  -- The first time this key is set, the value will be equal to incrementBy.\n\t  -- So we only need the expire command once\n\t  redis.call(\"PEXPIRE\", currentKey, window * 2 + 1000) -- Enough time to overlap with a new window + 1 second\n\tend\n\treturn {currentFields, previousFields, true}\n`;\nvar slidingWindowRemainingTokensScript2 = `\n\tlocal currentKey    = KEYS[1]           -- identifier including prefixes\n\tlocal previousKey   = KEYS[2]           -- key of the previous bucket\n\tlocal now         \t= ARGV[1]           -- current timestamp in milliseconds\n  \tlocal window      \t= ARGV[2]           -- interval in milliseconds\n\n\tlocal currentFields = redis.call(\"HGETALL\", currentKey)\n\tlocal requestsInCurrentWindow = 0\n\tfor i = 2, #currentFields, 2 do\n\trequestsInCurrentWindow = requestsInCurrentWindow + tonumber(currentFields[i])\n\tend\n\n\tlocal previousFields = redis.call(\"HGETALL\", previousKey)\n\tlocal requestsInPreviousWindow = 0\n\tfor i = 2, #previousFields, 2 do\n\trequestsInPreviousWindow = requestsInPreviousWindow + tonumber(previousFields[i])\n\tend\n\n\tlocal percentageInCurrent = ( now % window) / window\n  \trequestsInPreviousWindow = math.floor(( 1 - percentageInCurrent ) * requestsInPreviousWindow)\n\t\n\treturn requestsInCurrentWindow + requestsInPreviousWindow\n`;\n\n// src/lua-scripts/reset.ts\nvar resetScript = `\n      local pattern = KEYS[1]\n\n      -- Initialize cursor to start from 0\n      local cursor = \"0\"\n\n      repeat\n          -- Scan for keys matching the pattern\n          local scan_result = redis.call('SCAN', cursor, 'MATCH', pattern)\n\n          -- Extract cursor for the next iteration\n          cursor = scan_result[1]\n\n          -- Extract keys from the scan result\n          local keys = scan_result[2]\n\n          for i=1, #keys do\n          redis.call('DEL', keys[i])\n          end\n\n      -- Continue scanning until cursor is 0 (end of keyspace)\n      until cursor == \"0\"\n    `;\n\n// src/lua-scripts/hash.ts\nvar SCRIPTS = {\n  singleRegion: {\n    fixedWindow: {\n      limit: {\n        script: fixedWindowLimitScript,\n        hash: \"b13943e359636db027ad280f1def143f02158c13\"\n      },\n      getRemaining: {\n        script: fixedWindowRemainingTokensScript,\n        hash: \"8c4c341934502aee132643ffbe58ead3450e5208\"\n      }\n    },\n    slidingWindow: {\n      limit: {\n        script: slidingWindowLimitScript,\n        hash: \"e1391e429b699c780eb0480350cd5b7280fd9213\"\n      },\n      getRemaining: {\n        script: slidingWindowRemainingTokensScript,\n        hash: \"65a73ac5a05bf9712903bc304b77268980c1c417\"\n      }\n    },\n    tokenBucket: {\n      limit: {\n        script: tokenBucketLimitScript,\n        hash: \"5bece90aeef8189a8cfd28995b479529e270b3c6\"\n      },\n      getRemaining: {\n        script: tokenBucketRemainingTokensScript,\n        hash: \"a15be2bb1db2a15f7c82db06146f9d08983900d0\"\n      }\n    },\n    cachedFixedWindow: {\n      limit: {\n        script: cachedFixedWindowLimitScript,\n        hash: \"c26b12703dd137939b9a69a3a9b18e906a2d940f\"\n      },\n      getRemaining: {\n        script: cachedFixedWindowRemainingTokenScript,\n        hash: \"8e8f222ccae68b595ee6e3f3bf2199629a62b91a\"\n      }\n    }\n  },\n  multiRegion: {\n    fixedWindow: {\n      limit: {\n        script: fixedWindowLimitScript2,\n        hash: \"a8c14f3835aa87bd70e5e2116081b81664abcf5c\"\n      },\n      getRemaining: {\n        script: fixedWindowRemainingTokensScript2,\n        hash: \"8ab8322d0ed5fe5ac8eb08f0c2e4557f1b4816fd\"\n      }\n    },\n    slidingWindow: {\n      limit: {\n        script: slidingWindowLimitScript2,\n        hash: \"cb4fdc2575056df7c6d422764df0de3a08d6753b\"\n      },\n      getRemaining: {\n        script: slidingWindowRemainingTokensScript2,\n        hash: \"558c9306b7ec54abb50747fe0b17e5d44bd24868\"\n      }\n    }\n  }\n};\nvar RESET_SCRIPT = {\n  script: resetScript,\n  hash: \"54bd274ddc59fb3be0f42deee2f64322a10e2b50\"\n};\n\n// src/types.ts\nvar DenyListExtension = \"denyList\";\nvar IpDenyListKey = \"ipDenyList\";\nvar IpDenyListStatusKey = \"ipDenyListStatus\";\n\n// src/deny-list/scripts.ts\nvar checkDenyListScript = `\n  -- Checks if values provideed in ARGV are present in the deny lists.\n  -- This is done using the allDenyListsKey below.\n\n  -- Additionally, checks the status of the ip deny list using the\n  -- ipDenyListStatusKey below. Here are the possible states of the\n  -- ipDenyListStatusKey key:\n  -- * status == -1: set to \"disabled\" with no TTL\n  -- * status == -2: not set, meaning that is was set before but expired\n  -- * status  >  0: set to \"valid\", with a TTL\n  --\n  -- In the case of status == -2, we set the status to \"pending\" with\n  -- 30 second ttl. During this time, the process which got status == -2\n  -- will update the ip deny list.\n\n  local allDenyListsKey     = KEYS[1]\n  local ipDenyListStatusKey = KEYS[2]\n\n  local results = redis.call('SMISMEMBER', allDenyListsKey, unpack(ARGV))\n  local status  = redis.call('TTL', ipDenyListStatusKey)\n  if status == -2 then\n    redis.call('SETEX', ipDenyListStatusKey, 30, \"pending\")\n  end\n\n  return { results, status }\n`;\n\n// src/deny-list/ip-deny-list.ts\nvar ip_deny_list_exports = {};\n__export(ip_deny_list_exports, {\n  ThresholdError: () => ThresholdError,\n  disableIpDenyList: () => disableIpDenyList,\n  updateIpDenyList: () => updateIpDenyList\n});\n\n// src/deny-list/time.ts\nvar MILLISECONDS_IN_HOUR = 60 * 60 * 1e3;\nvar MILLISECONDS_IN_DAY = 24 * MILLISECONDS_IN_HOUR;\nvar MILLISECONDS_TO_2AM = 2 * MILLISECONDS_IN_HOUR;\nvar getIpListTTL = (time) => {\n  const now = time || Date.now();\n  const timeSinceLast2AM = (now - MILLISECONDS_TO_2AM) % MILLISECONDS_IN_DAY;\n  return MILLISECONDS_IN_DAY - timeSinceLast2AM;\n};\n\n// src/deny-list/ip-deny-list.ts\nvar baseUrl = \"https://raw.githubusercontent.com/stamparm/ipsum/master/levels\";\nvar ThresholdError = class extends Error {\n  constructor(threshold) {\n    super(`Allowed threshold values are from 1 to 8, 1 and 8 included. Received: ${threshold}`);\n    this.name = \"ThresholdError\";\n  }\n};\nvar getIpDenyList = async (threshold) => {\n  if (typeof threshold !== \"number\" || threshold < 1 || threshold > 8) {\n    throw new ThresholdError(threshold);\n  }\n  try {\n    const response = await fetch(`${baseUrl}/${threshold}.txt`);\n    if (!response.ok) {\n      throw new Error(`Error fetching data: ${response.statusText}`);\n    }\n    const data = await response.text();\n    const lines = data.split(\"\\n\");\n    return lines.filter((value) => value.length > 0);\n  } catch (error) {\n    throw new Error(`Failed to fetch ip deny list: ${error}`);\n  }\n};\nvar updateIpDenyList = async (redis, prefix, threshold, ttl) => {\n  const allIps = await getIpDenyList(threshold);\n  const allDenyLists = [prefix, DenyListExtension, \"all\"].join(\":\");\n  const ipDenyList = [prefix, DenyListExtension, IpDenyListKey].join(\":\");\n  const statusKey = [prefix, IpDenyListStatusKey].join(\":\");\n  const transaction = redis.multi();\n  transaction.sdiffstore(allDenyLists, allDenyLists, ipDenyList);\n  transaction.del(ipDenyList);\n  transaction.sadd(ipDenyList, allIps.at(0), ...allIps.slice(1));\n  transaction.sdiffstore(ipDenyList, ipDenyList, allDenyLists);\n  transaction.sunionstore(allDenyLists, allDenyLists, ipDenyList);\n  transaction.set(statusKey, \"valid\", { px: ttl ?? getIpListTTL() });\n  return await transaction.exec();\n};\nvar disableIpDenyList = async (redis, prefix) => {\n  const allDenyListsKey = [prefix, DenyListExtension, \"all\"].join(\":\");\n  const ipDenyListKey = [prefix, DenyListExtension, IpDenyListKey].join(\":\");\n  const statusKey = [prefix, IpDenyListStatusKey].join(\":\");\n  const transaction = redis.multi();\n  transaction.sdiffstore(allDenyListsKey, allDenyListsKey, ipDenyListKey);\n  transaction.del(ipDenyListKey);\n  transaction.set(statusKey, \"disabled\");\n  return await transaction.exec();\n};\n\n// src/deny-list/deny-list.ts\nvar denyListCache = new Cache(/* @__PURE__ */ new Map());\nvar checkDenyListCache = (members) => {\n  return members.find(\n    (member) => denyListCache.isBlocked(member).blocked\n  );\n};\nvar blockMember = (member) => {\n  if (denyListCache.size() > 1e3)\n    denyListCache.empty();\n  denyListCache.blockUntil(member, Date.now() + 6e4);\n};\nvar checkDenyList = async (redis, prefix, members) => {\n  const [deniedValues, ipDenyListStatus] = await redis.eval(\n    checkDenyListScript,\n    [\n      [prefix, DenyListExtension, \"all\"].join(\":\"),\n      [prefix, IpDenyListStatusKey].join(\":\")\n    ],\n    members\n  );\n  let deniedValue = void 0;\n  deniedValues.map((memberDenied, index) => {\n    if (memberDenied) {\n      blockMember(members[index]);\n      deniedValue = members[index];\n    }\n  });\n  return {\n    deniedValue,\n    invalidIpDenyList: ipDenyListStatus === -2\n  };\n};\nvar resolveLimitPayload = (redis, prefix, [ratelimitResponse, denyListResponse], threshold) => {\n  if (denyListResponse.deniedValue) {\n    ratelimitResponse.success = false;\n    ratelimitResponse.remaining = 0;\n    ratelimitResponse.reason = \"denyList\";\n    ratelimitResponse.deniedValue = denyListResponse.deniedValue;\n  }\n  if (denyListResponse.invalidIpDenyList) {\n    const updatePromise = updateIpDenyList(redis, prefix, threshold);\n    ratelimitResponse.pending = Promise.all([\n      ratelimitResponse.pending,\n      updatePromise\n    ]);\n  }\n  return ratelimitResponse;\n};\nvar defaultDeniedResponse = (deniedValue) => {\n  return {\n    success: false,\n    limit: 0,\n    remaining: 0,\n    reset: 0,\n    pending: Promise.resolve(),\n    reason: \"denyList\",\n    deniedValue\n  };\n};\n\n// src/ratelimit.ts\nvar Ratelimit = class {\n  limiter;\n  ctx;\n  prefix;\n  timeout;\n  primaryRedis;\n  analytics;\n  enableProtection;\n  denyListThreshold;\n  constructor(config) {\n    this.ctx = config.ctx;\n    this.limiter = config.limiter;\n    this.timeout = config.timeout ?? 5e3;\n    this.prefix = config.prefix ?? \"@upstash/ratelimit\";\n    this.enableProtection = config.enableProtection ?? false;\n    this.denyListThreshold = config.denyListThreshold ?? 6;\n    this.primaryRedis = \"redis\" in this.ctx ? this.ctx.redis : this.ctx.regionContexts[0].redis;\n    this.analytics = config.analytics ? new Analytics({\n      redis: this.primaryRedis,\n      prefix: this.prefix\n    }) : void 0;\n    if (config.ephemeralCache instanceof Map) {\n      this.ctx.cache = new Cache(config.ephemeralCache);\n    } else if (config.ephemeralCache === void 0) {\n      this.ctx.cache = new Cache(/* @__PURE__ */ new Map());\n    }\n  }\n  /**\n   * Determine if a request should pass or be rejected based on the identifier and previously chosen ratelimit.\n   *\n   * Use this if you want to reject all requests that you can not handle right now.\n   *\n   * @example\n   * ```ts\n   *  const ratelimit = new Ratelimit({\n   *    redis: Redis.fromEnv(),\n   *    limiter: Ratelimit.slidingWindow(10, \"10 s\")\n   *  })\n   *\n   *  const { success } = await ratelimit.limit(id)\n   *  if (!success){\n   *    return \"Nope\"\n   *  }\n   *  return \"Yes\"\n   * ```\n   *\n   * @param req.rate - The rate at which tokens will be added or consumed from the token bucket. A higher rate allows for more requests to be processed. Defaults to 1 token per interval if not specified.\n   *\n   * Usage with `req.rate`\n   * @example\n   * ```ts\n   *  const ratelimit = new Ratelimit({\n   *    redis: Redis.fromEnv(),\n   *    limiter: Ratelimit.slidingWindow(100, \"10 s\")\n   *  })\n   *\n   *  const { success } = await ratelimit.limit(id, {rate: 10})\n   *  if (!success){\n   *    return \"Nope\"\n   *  }\n   *  return \"Yes\"\n   * ```\n   */\n  limit = async (identifier, req) => {\n    let timeoutId = null;\n    try {\n      const response = this.getRatelimitResponse(identifier, req);\n      const { responseArray, newTimeoutId } = this.applyTimeout(response);\n      timeoutId = newTimeoutId;\n      const timedResponse = await Promise.race(responseArray);\n      const finalResponse = this.submitAnalytics(timedResponse, identifier, req);\n      return finalResponse;\n    } finally {\n      if (timeoutId) {\n        clearTimeout(timeoutId);\n      }\n    }\n  };\n  /**\n   * Block until the request may pass or timeout is reached.\n   *\n   * This method returns a promise that resolves as soon as the request may be processed\n   * or after the timeout has been reached.\n   *\n   * Use this if you want to delay the request until it is ready to get processed.\n   *\n   * @example\n   * ```ts\n   *  const ratelimit = new Ratelimit({\n   *    redis: Redis.fromEnv(),\n   *    limiter: Ratelimit.slidingWindow(10, \"10 s\")\n   *  })\n   *\n   *  const { success } = await ratelimit.blockUntilReady(id, 60_000)\n   *  if (!success){\n   *    return \"Nope\"\n   *  }\n   *  return \"Yes\"\n   * ```\n   */\n  blockUntilReady = async (identifier, timeout) => {\n    if (timeout <= 0) {\n      throw new Error(\"timeout must be positive\");\n    }\n    let res;\n    const deadline = Date.now() + timeout;\n    while (true) {\n      res = await this.limit(identifier);\n      if (res.success) {\n        break;\n      }\n      if (res.reset === 0) {\n        throw new Error(\"This should not happen\");\n      }\n      const wait = Math.min(res.reset, deadline) - Date.now();\n      await new Promise((r) => setTimeout(r, wait));\n      if (Date.now() > deadline) {\n        break;\n      }\n    }\n    return res;\n  };\n  resetUsedTokens = async (identifier) => {\n    const pattern = [this.prefix, identifier].join(\":\");\n    await this.limiter().resetTokens(this.ctx, pattern);\n  };\n  /**\n   * Returns the remaining token count together with a reset timestamps\n   * \n   * @param identifier identifir to check\n   * @returns object with `remaining` and reset fields. `remaining` denotes\n   *          the remaining tokens and reset denotes the timestamp when the\n   *          tokens reset.\n   */\n  getRemaining = async (identifier) => {\n    const pattern = [this.prefix, identifier].join(\":\");\n    return await this.limiter().getRemaining(this.ctx, pattern);\n  };\n  /**\n   * Checks if the identifier or the values in req are in the deny list cache.\n   * If so, returns the default denied response.\n   * \n   * Otherwise, calls redis to check the rate limit and deny list. Returns after\n   * resolving the result. Resolving is overriding the rate limit result if\n   * the some value is in deny list.\n   * \n   * @param identifier identifier to block\n   * @param req options with ip, user agent, country, rate and geo info\n   * @returns rate limit response\n   */\n  getRatelimitResponse = async (identifier, req) => {\n    const key = this.getKey(identifier);\n    const definedMembers = this.getDefinedMembers(identifier, req);\n    const deniedValue = checkDenyListCache(definedMembers);\n    const result = deniedValue ? [defaultDeniedResponse(deniedValue), { deniedValue, invalidIpDenyList: false }] : await Promise.all([\n      this.limiter().limit(this.ctx, key, req?.rate),\n      this.enableProtection ? checkDenyList(this.primaryRedis, this.prefix, definedMembers) : { deniedValue: void 0, invalidIpDenyList: false }\n    ]);\n    return resolveLimitPayload(this.primaryRedis, this.prefix, result, this.denyListThreshold);\n  };\n  /**\n   * Creates an array with the original response promise and a timeout promise\n   * if this.timeout > 0.\n   * \n   * @param response Ratelimit response promise\n   * @returns array with the response and timeout promise. also includes the timeout id\n   */\n  applyTimeout = (response) => {\n    let newTimeoutId = null;\n    const responseArray = [response];\n    if (this.timeout > 0) {\n      const timeoutResponse = new Promise((resolve) => {\n        newTimeoutId = setTimeout(() => {\n          resolve({\n            success: true,\n            limit: 0,\n            remaining: 0,\n            reset: 0,\n            pending: Promise.resolve(),\n            reason: \"timeout\"\n          });\n        }, this.timeout);\n      });\n      responseArray.push(timeoutResponse);\n    }\n    return {\n      responseArray,\n      newTimeoutId\n    };\n  };\n  /**\n   * submits analytics if this.analytics is set\n   * \n   * @param ratelimitResponse final rate limit response\n   * @param identifier identifier to submit\n   * @param req limit options\n   * @returns rate limit response after updating the .pending field\n   */\n  submitAnalytics = (ratelimitResponse, identifier, req) => {\n    if (this.analytics) {\n      try {\n        const geo = req ? this.analytics.extractGeo(req) : void 0;\n        const analyticsP = this.analytics.record({\n          identifier: ratelimitResponse.reason === \"denyList\" ? ratelimitResponse.deniedValue : identifier,\n          time: Date.now(),\n          success: ratelimitResponse.reason === \"denyList\" ? \"denied\" : ratelimitResponse.success,\n          ...geo\n        }).catch((error) => {\n          let errorMessage = \"Failed to record analytics\";\n          if (`${error}`.includes(\"WRONGTYPE\")) {\n            errorMessage = `\n    Failed to record analytics. See the information below:\n\n    This can occur when you uprade to Ratelimit version 1.1.2\n    or later from an earlier version.\n\n    This occurs simply because the way we store analytics data\n    has changed. To avoid getting this error, disable analytics\n    for *an hour*, then simply enable it back.\n\n    `;\n          }\n          console.warn(errorMessage, error);\n        });\n        ratelimitResponse.pending = Promise.all([ratelimitResponse.pending, analyticsP]);\n      } catch (error) {\n        console.warn(\"Failed to record analytics\", error);\n      }\n      ;\n    }\n    ;\n    return ratelimitResponse;\n  };\n  getKey = (identifier) => {\n    return [this.prefix, identifier].join(\":\");\n  };\n  /**\n   * returns a list of defined values from\n   * [identifier, req.ip, req.userAgent, req.country]\n   * \n   * @param identifier identifier\n   * @param req limit options\n   * @returns list of defined values\n   */\n  getDefinedMembers = (identifier, req) => {\n    const members = [identifier, req?.ip, req?.userAgent, req?.country];\n    return members.filter(Boolean);\n  };\n};\n\n// src/multi.ts\nfunction randomId() {\n  let result = \"\";\n  const characters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\";\n  const charactersLength = characters.length;\n  for (let i = 0; i < 16; i++) {\n    result += characters.charAt(Math.floor(Math.random() * charactersLength));\n  }\n  return result;\n}\nvar MultiRegionRatelimit = class extends Ratelimit {\n  /**\n   * Create a new Ratelimit instance by providing a `@upstash/redis` instance and the algorithn of your choice.\n   */\n  constructor(config) {\n    super({\n      prefix: config.prefix,\n      limiter: config.limiter,\n      timeout: config.timeout,\n      analytics: config.analytics,\n      ctx: {\n        regionContexts: config.redis.map((redis) => ({\n          redis\n        })),\n        cache: config.ephemeralCache ? new Cache(config.ephemeralCache) : void 0\n      }\n    });\n  }\n  /**\n   * Each request inside a fixed time increases a counter.\n   * Once the counter reaches the maximum allowed number, all further requests are\n   * rejected.\n   *\n   * **Pro:**\n   *\n   * - Newer requests are not starved by old ones.\n   * - Low storage cost.\n   *\n   * **Con:**\n   *\n   * A burst of requests near the boundary of a window can result in a very\n   * high request rate because two windows will be filled with requests quickly.\n   *\n   * @param tokens - How many requests a user can make in each time window.\n   * @param window - A fixed timeframe\n   */\n  static fixedWindow(tokens, window) {\n    const windowDuration = ms(window);\n    return () => ({\n      async limit(ctx, identifier, rate) {\n        if (ctx.cache) {\n          const { blocked, reset: reset2 } = ctx.cache.isBlocked(identifier);\n          if (blocked) {\n            return {\n              success: false,\n              limit: tokens,\n              remaining: 0,\n              reset: reset2,\n              pending: Promise.resolve(),\n              reason: \"cacheBlock\"\n            };\n          }\n        }\n        const requestId = randomId();\n        const bucket = Math.floor(Date.now() / windowDuration);\n        const key = [identifier, bucket].join(\":\");\n        const incrementBy = rate ? Math.max(1, rate) : 1;\n        const dbs = ctx.regionContexts.map((regionContext) => ({\n          redis: regionContext.redis,\n          request: safeEval(\n            regionContext,\n            SCRIPTS.multiRegion.fixedWindow.limit,\n            [key],\n            [requestId, windowDuration, incrementBy]\n          )\n        }));\n        const firstResponse = await Promise.any(dbs.map((s) => s.request));\n        const usedTokens = firstResponse.reduce((accTokens, usedToken, index) => {\n          let parsedToken = 0;\n          if (index % 2) {\n            parsedToken = Number.parseInt(usedToken);\n          }\n          return accTokens + parsedToken;\n        }, 0);\n        const remaining = tokens - usedTokens;\n        async function sync() {\n          const individualIDs = await Promise.all(dbs.map((s) => s.request));\n          const allIDs = [...new Set(\n            individualIDs.flat().reduce((acc, curr, index) => {\n              if (index % 2 === 0) {\n                acc.push(curr);\n              }\n              return acc;\n            }, [])\n          ).values()];\n          for (const db of dbs) {\n            const usedDbTokensRequest = await db.request;\n            const usedDbTokens = usedDbTokensRequest.reduce(\n              (accTokens, usedToken, index) => {\n                let parsedToken = 0;\n                if (index % 2) {\n                  parsedToken = Number.parseInt(usedToken);\n                }\n                return accTokens + parsedToken;\n              },\n              0\n            );\n            const dbIdsRequest = await db.request;\n            const dbIds = dbIdsRequest.reduce((ids, currentId, index) => {\n              if (index % 2 === 0) {\n                ids.push(currentId);\n              }\n              return ids;\n            }, []);\n            if (usedDbTokens >= tokens) {\n              continue;\n            }\n            const diff = allIDs.filter((id) => !dbIds.includes(id));\n            if (diff.length === 0) {\n              continue;\n            }\n            for (const requestId2 of diff) {\n              await db.redis.hset(key, { [requestId2]: incrementBy });\n            }\n          }\n        }\n        const success = remaining > 0;\n        const reset = (bucket + 1) * windowDuration;\n        if (ctx.cache && !success) {\n          ctx.cache.blockUntil(identifier, reset);\n        }\n        return {\n          success,\n          limit: tokens,\n          remaining,\n          reset,\n          pending: sync()\n        };\n      },\n      async getRemaining(ctx, identifier) {\n        const bucket = Math.floor(Date.now() / windowDuration);\n        const key = [identifier, bucket].join(\":\");\n        const dbs = ctx.regionContexts.map((regionContext) => ({\n          redis: regionContext.redis,\n          request: safeEval(\n            regionContext,\n            SCRIPTS.multiRegion.fixedWindow.getRemaining,\n            [key],\n            [null]\n          )\n        }));\n        const firstResponse = await Promise.any(dbs.map((s) => s.request));\n        const usedTokens = firstResponse.reduce((accTokens, usedToken, index) => {\n          let parsedToken = 0;\n          if (index % 2) {\n            parsedToken = Number.parseInt(usedToken);\n          }\n          return accTokens + parsedToken;\n        }, 0);\n        return {\n          remaining: Math.max(0, tokens - usedTokens),\n          reset: (bucket + 1) * windowDuration\n        };\n      },\n      async resetTokens(ctx, identifier) {\n        const pattern = [identifier, \"*\"].join(\":\");\n        if (ctx.cache) {\n          ctx.cache.pop(identifier);\n        }\n        await Promise.all(ctx.regionContexts.map((regionContext) => {\n          safeEval(\n            regionContext,\n            RESET_SCRIPT,\n            [pattern],\n            [null]\n          );\n        }));\n      }\n    });\n  }\n  /**\n   * Combined approach of `slidingLogs` and `fixedWindow` with lower storage\n   * costs than `slidingLogs` and improved boundary behavior by calculating a\n   * weighted score between two windows.\n   *\n   * **Pro:**\n   *\n   * Good performance allows this to scale to very high loads.\n   *\n   * **Con:**\n   *\n   * Nothing major.\n   *\n   * @param tokens - How many requests a user can make in each time window.\n   * @param window - The duration in which the user can max X requests.\n   */\n  static slidingWindow(tokens, window) {\n    const windowSize = ms(window);\n    const windowDuration = ms(window);\n    return () => ({\n      async limit(ctx, identifier, rate) {\n        if (ctx.cache) {\n          const { blocked, reset: reset2 } = ctx.cache.isBlocked(identifier);\n          if (blocked) {\n            return {\n              success: false,\n              limit: tokens,\n              remaining: 0,\n              reset: reset2,\n              pending: Promise.resolve(),\n              reason: \"cacheBlock\"\n            };\n          }\n        }\n        const requestId = randomId();\n        const now = Date.now();\n        const currentWindow = Math.floor(now / windowSize);\n        const currentKey = [identifier, currentWindow].join(\":\");\n        const previousWindow = currentWindow - 1;\n        const previousKey = [identifier, previousWindow].join(\":\");\n        const incrementBy = rate ? Math.max(1, rate) : 1;\n        const dbs = ctx.regionContexts.map((regionContext) => ({\n          redis: regionContext.redis,\n          request: safeEval(\n            regionContext,\n            SCRIPTS.multiRegion.slidingWindow.limit,\n            [currentKey, previousKey],\n            [tokens, now, windowDuration, requestId, incrementBy]\n            // lua seems to return `1` for true and `null` for false\n          )\n        }));\n        const percentageInCurrent = now % windowDuration / windowDuration;\n        const [current, previous, success] = await Promise.any(dbs.map((s) => s.request));\n        if (success) {\n          current.push(requestId, incrementBy.toString());\n        }\n        const previousUsedTokens = previous.reduce((accTokens, usedToken, index) => {\n          let parsedToken = 0;\n          if (index % 2) {\n            parsedToken = Number.parseInt(usedToken);\n          }\n          return accTokens + parsedToken;\n        }, 0);\n        const currentUsedTokens = current.reduce((accTokens, usedToken, index) => {\n          let parsedToken = 0;\n          if (index % 2) {\n            parsedToken = Number.parseInt(usedToken);\n          }\n          return accTokens + parsedToken;\n        }, 0);\n        const previousPartialUsed = Math.ceil(previousUsedTokens * (1 - percentageInCurrent));\n        const usedTokens = previousPartialUsed + currentUsedTokens;\n        const remaining = tokens - usedTokens;\n        async function sync() {\n          const res = await Promise.all(dbs.map((s) => s.request));\n          const allCurrentIds = [...new Set(\n            res.flatMap(([current2]) => current2).reduce((acc, curr, index) => {\n              if (index % 2 === 0) {\n                acc.push(curr);\n              }\n              return acc;\n            }, [])\n          ).values()];\n          for (const db of dbs) {\n            const [current2, _previous, _success] = await db.request;\n            const dbIds = current2.reduce((ids, currentId, index) => {\n              if (index % 2 === 0) {\n                ids.push(currentId);\n              }\n              return ids;\n            }, []);\n            const usedDbTokens = current2.reduce((accTokens, usedToken, index) => {\n              let parsedToken = 0;\n              if (index % 2) {\n                parsedToken = Number.parseInt(usedToken);\n              }\n              return accTokens + parsedToken;\n            }, 0);\n            if (usedDbTokens >= tokens) {\n              continue;\n            }\n            const diff = allCurrentIds.filter((id) => !dbIds.includes(id));\n            if (diff.length === 0) {\n              continue;\n            }\n            for (const requestId2 of diff) {\n              await db.redis.hset(currentKey, { [requestId2]: incrementBy });\n            }\n          }\n        }\n        const reset = (currentWindow + 1) * windowDuration;\n        if (ctx.cache && !success) {\n          ctx.cache.blockUntil(identifier, reset);\n        }\n        return {\n          success: Boolean(success),\n          limit: tokens,\n          remaining: Math.max(0, remaining),\n          reset,\n          pending: sync()\n        };\n      },\n      async getRemaining(ctx, identifier) {\n        const now = Date.now();\n        const currentWindow = Math.floor(now / windowSize);\n        const currentKey = [identifier, currentWindow].join(\":\");\n        const previousWindow = currentWindow - 1;\n        const previousKey = [identifier, previousWindow].join(\":\");\n        const dbs = ctx.regionContexts.map((regionContext) => ({\n          redis: regionContext.redis,\n          request: safeEval(\n            regionContext,\n            SCRIPTS.multiRegion.slidingWindow.getRemaining,\n            [currentKey, previousKey],\n            [now, windowSize]\n            // lua seems to return `1` for true and `null` for false\n          )\n        }));\n        const usedTokens = await Promise.any(dbs.map((s) => s.request));\n        return {\n          remaining: Math.max(0, tokens - usedTokens),\n          reset: (currentWindow + 1) * windowSize\n        };\n      },\n      async resetTokens(ctx, identifier) {\n        const pattern = [identifier, \"*\"].join(\":\");\n        if (ctx.cache) {\n          ctx.cache.pop(identifier);\n        }\n        await Promise.all(ctx.regionContexts.map((regionContext) => {\n          safeEval(\n            regionContext,\n            RESET_SCRIPT,\n            [pattern],\n            [null]\n          );\n        }));\n      }\n    });\n  }\n};\n\n// src/single.ts\nvar RegionRatelimit = class extends Ratelimit {\n  /**\n   * Create a new Ratelimit instance by providing a `@upstash/redis` instance and the algorithm of your choice.\n   */\n  constructor(config) {\n    super({\n      prefix: config.prefix,\n      limiter: config.limiter,\n      timeout: config.timeout,\n      analytics: config.analytics,\n      ctx: {\n        redis: config.redis\n      },\n      ephemeralCache: config.ephemeralCache,\n      enableProtection: config.enableProtection,\n      denyListThreshold: config.denyListThreshold\n    });\n  }\n  /**\n   * Each request inside a fixed time increases a counter.\n   * Once the counter reaches the maximum allowed number, all further requests are\n   * rejected.\n   *\n   * **Pro:**\n   *\n   * - Newer requests are not starved by old ones.\n   * - Low storage cost.\n   *\n   * **Con:**\n   *\n   * A burst of requests near the boundary of a window can result in a very\n   * high request rate because two windows will be filled with requests quickly.\n   *\n   * @param tokens - How many requests a user can make in each time window.\n   * @param window - A fixed timeframe\n   */\n  static fixedWindow(tokens, window) {\n    const windowDuration = ms(window);\n    return () => ({\n      async limit(ctx, identifier, rate) {\n        const bucket = Math.floor(Date.now() / windowDuration);\n        const key = [identifier, bucket].join(\":\");\n        if (ctx.cache) {\n          const { blocked, reset: reset2 } = ctx.cache.isBlocked(identifier);\n          if (blocked) {\n            return {\n              success: false,\n              limit: tokens,\n              remaining: 0,\n              reset: reset2,\n              pending: Promise.resolve(),\n              reason: \"cacheBlock\"\n            };\n          }\n        }\n        const incrementBy = rate ? Math.max(1, rate) : 1;\n        const usedTokensAfterUpdate = await safeEval(\n          ctx,\n          SCRIPTS.singleRegion.fixedWindow.limit,\n          [key],\n          [windowDuration, incrementBy]\n        );\n        const success = usedTokensAfterUpdate <= tokens;\n        const remainingTokens = Math.max(0, tokens - usedTokensAfterUpdate);\n        const reset = (bucket + 1) * windowDuration;\n        if (ctx.cache && !success) {\n          ctx.cache.blockUntil(identifier, reset);\n        }\n        return {\n          success,\n          limit: tokens,\n          remaining: remainingTokens,\n          reset,\n          pending: Promise.resolve()\n        };\n      },\n      async getRemaining(ctx, identifier) {\n        const bucket = Math.floor(Date.now() / windowDuration);\n        const key = [identifier, bucket].join(\":\");\n        const usedTokens = await safeEval(\n          ctx,\n          SCRIPTS.singleRegion.fixedWindow.getRemaining,\n          [key],\n          [null]\n        );\n        return {\n          remaining: Math.max(0, tokens - usedTokens),\n          reset: (bucket + 1) * windowDuration\n        };\n      },\n      async resetTokens(ctx, identifier) {\n        const pattern = [identifier, \"*\"].join(\":\");\n        if (ctx.cache) {\n          ctx.cache.pop(identifier);\n        }\n        await safeEval(\n          ctx,\n          RESET_SCRIPT,\n          [pattern],\n          [null]\n        );\n      }\n    });\n  }\n  /**\n   * Combined approach of `slidingLogs` and `fixedWindow` with lower storage\n   * costs than `slidingLogs` and improved boundary behavior by calculating a\n   * weighted score between two windows.\n   *\n   * **Pro:**\n   *\n   * Good performance allows this to scale to very high loads.\n   *\n   * **Con:**\n   *\n   * Nothing major.\n   *\n   * @param tokens - How many requests a user can make in each time window.\n   * @param window - The duration in which the user can max X requests.\n   */\n  static slidingWindow(tokens, window) {\n    const windowSize = ms(window);\n    return () => ({\n      async limit(ctx, identifier, rate) {\n        const now = Date.now();\n        const currentWindow = Math.floor(now / windowSize);\n        const currentKey = [identifier, currentWindow].join(\":\");\n        const previousWindow = currentWindow - 1;\n        const previousKey = [identifier, previousWindow].join(\":\");\n        if (ctx.cache) {\n          const { blocked, reset: reset2 } = ctx.cache.isBlocked(identifier);\n          if (blocked) {\n            return {\n              success: false,\n              limit: tokens,\n              remaining: 0,\n              reset: reset2,\n              pending: Promise.resolve(),\n              reason: \"cacheBlock\"\n            };\n          }\n        }\n        const incrementBy = rate ? Math.max(1, rate) : 1;\n        const remainingTokens = await safeEval(\n          ctx,\n          SCRIPTS.singleRegion.slidingWindow.limit,\n          [currentKey, previousKey],\n          [tokens, now, windowSize, incrementBy]\n        );\n        const success = remainingTokens >= 0;\n        const reset = (currentWindow + 1) * windowSize;\n        if (ctx.cache && !success) {\n          ctx.cache.blockUntil(identifier, reset);\n        }\n        return {\n          success,\n          limit: tokens,\n          remaining: Math.max(0, remainingTokens),\n          reset,\n          pending: Promise.resolve()\n        };\n      },\n      async getRemaining(ctx, identifier) {\n        const now = Date.now();\n        const currentWindow = Math.floor(now / windowSize);\n        const currentKey = [identifier, currentWindow].join(\":\");\n        const previousWindow = currentWindow - 1;\n        const previousKey = [identifier, previousWindow].join(\":\");\n        const usedTokens = await safeEval(\n          ctx,\n          SCRIPTS.singleRegion.slidingWindow.getRemaining,\n          [currentKey, previousKey],\n          [now, windowSize]\n        );\n        return {\n          remaining: Math.max(0, tokens - usedTokens),\n          reset: (currentWindow + 1) * windowSize\n        };\n      },\n      async resetTokens(ctx, identifier) {\n        const pattern = [identifier, \"*\"].join(\":\");\n        if (ctx.cache) {\n          ctx.cache.pop(identifier);\n        }\n        await safeEval(\n          ctx,\n          RESET_SCRIPT,\n          [pattern],\n          [null]\n        );\n      }\n    });\n  }\n  /**\n   * You have a bucket filled with `{maxTokens}` tokens that refills constantly\n   * at `{refillRate}` per `{interval}`.\n   * Every request will remove one token from the bucket and if there is no\n   * token to take, the request is rejected.\n   *\n   * **Pro:**\n   *\n   * - Bursts of requests are smoothed out and you can process them at a constant\n   * rate.\n   * - Allows to set a higher initial burst limit by setting `maxTokens` higher\n   * than `refillRate`\n   */\n  static tokenBucket(refillRate, interval, maxTokens) {\n    const intervalDuration = ms(interval);\n    return () => ({\n      async limit(ctx, identifier, rate) {\n        if (ctx.cache) {\n          const { blocked, reset: reset2 } = ctx.cache.isBlocked(identifier);\n          if (blocked) {\n            return {\n              success: false,\n              limit: maxTokens,\n              remaining: 0,\n              reset: reset2,\n              pending: Promise.resolve(),\n              reason: \"cacheBlock\"\n            };\n          }\n        }\n        const now = Date.now();\n        const incrementBy = rate ? Math.max(1, rate) : 1;\n        const [remaining, reset] = await safeEval(\n          ctx,\n          SCRIPTS.singleRegion.tokenBucket.limit,\n          [identifier],\n          [maxTokens, intervalDuration, refillRate, now, incrementBy]\n        );\n        const success = remaining >= 0;\n        if (ctx.cache && !success) {\n          ctx.cache.blockUntil(identifier, reset);\n        }\n        return {\n          success,\n          limit: maxTokens,\n          remaining,\n          reset,\n          pending: Promise.resolve()\n        };\n      },\n      async getRemaining(ctx, identifier) {\n        const [remainingTokens, refilledAt] = await safeEval(\n          ctx,\n          SCRIPTS.singleRegion.tokenBucket.getRemaining,\n          [identifier],\n          [maxTokens]\n        );\n        const freshRefillAt = Date.now() + intervalDuration;\n        const identifierRefillsAt = refilledAt + intervalDuration;\n        return {\n          remaining: remainingTokens,\n          reset: refilledAt === tokenBucketIdentifierNotFound ? freshRefillAt : identifierRefillsAt\n        };\n      },\n      async resetTokens(ctx, identifier) {\n        const pattern = identifier;\n        if (ctx.cache) {\n          ctx.cache.pop(identifier);\n        }\n        await safeEval(\n          ctx,\n          RESET_SCRIPT,\n          [pattern],\n          [null]\n        );\n      }\n    });\n  }\n  /**\n   * cachedFixedWindow first uses the local cache to decide if a request may pass and then updates\n   * it asynchronously.\n   * This is experimental and not yet recommended for production use.\n   *\n   * @experimental\n   *\n   * Each request inside a fixed time increases a counter.\n   * Once the counter reaches the maximum allowed number, all further requests are\n   * rejected.\n   *\n   * **Pro:**\n   *\n   * - Newer requests are not starved by old ones.\n   * - Low storage cost.\n   *\n   * **Con:**\n   *\n   * A burst of requests near the boundary of a window can result in a very\n   * high request rate because two windows will be filled with requests quickly.\n   *\n   * @param tokens - How many requests a user can make in each time window.\n   * @param window - A fixed timeframe\n   */\n  static cachedFixedWindow(tokens, window) {\n    const windowDuration = ms(window);\n    return () => ({\n      async limit(ctx, identifier, rate) {\n        if (!ctx.cache) {\n          throw new Error(\"This algorithm requires a cache\");\n        }\n        const bucket = Math.floor(Date.now() / windowDuration);\n        const key = [identifier, bucket].join(\":\");\n        const reset = (bucket + 1) * windowDuration;\n        const incrementBy = rate ? Math.max(1, rate) : 1;\n        const hit = typeof ctx.cache.get(key) === \"number\";\n        if (hit) {\n          const cachedTokensAfterUpdate = ctx.cache.incr(key);\n          const success = cachedTokensAfterUpdate < tokens;\n          const pending = success ? safeEval(\n            ctx,\n            SCRIPTS.singleRegion.cachedFixedWindow.limit,\n            [key],\n            [windowDuration, incrementBy]\n          ) : Promise.resolve();\n          return {\n            success,\n            limit: tokens,\n            remaining: tokens - cachedTokensAfterUpdate,\n            reset,\n            pending\n          };\n        }\n        const usedTokensAfterUpdate = await safeEval(\n          ctx,\n          SCRIPTS.singleRegion.cachedFixedWindow.limit,\n          [key],\n          [windowDuration, incrementBy]\n        );\n        ctx.cache.set(key, usedTokensAfterUpdate);\n        const remaining = tokens - usedTokensAfterUpdate;\n        return {\n          success: remaining >= 0,\n          limit: tokens,\n          remaining,\n          reset,\n          pending: Promise.resolve()\n        };\n      },\n      async getRemaining(ctx, identifier) {\n        if (!ctx.cache) {\n          throw new Error(\"This algorithm requires a cache\");\n        }\n        const bucket = Math.floor(Date.now() / windowDuration);\n        const key = [identifier, bucket].join(\":\");\n        const hit = typeof ctx.cache.get(key) === \"number\";\n        if (hit) {\n          const cachedUsedTokens = ctx.cache.get(key) ?? 0;\n          return {\n            remaining: Math.max(0, tokens - cachedUsedTokens),\n            reset: (bucket + 1) * windowDuration\n          };\n        }\n        const usedTokens = await safeEval(\n          ctx,\n          SCRIPTS.singleRegion.cachedFixedWindow.getRemaining,\n          [key],\n          [null]\n        );\n        return {\n          remaining: Math.max(0, tokens - usedTokens),\n          reset: (bucket + 1) * windowDuration\n        };\n      },\n      async resetTokens(ctx, identifier) {\n        if (!ctx.cache) {\n          throw new Error(\"This algorithm requires a cache\");\n        }\n        const bucket = Math.floor(Date.now() / windowDuration);\n        const key = [identifier, bucket].join(\":\");\n        ctx.cache.pop(key);\n        const pattern = [identifier, \"*\"].join(\":\");\n        await safeEval(\n          ctx,\n          RESET_SCRIPT,\n          [pattern],\n          [null]\n        );\n      }\n    });\n  }\n};\n// Annotate the CommonJS export names for ESM import in node:\n0 && (module.exports = {\n  Analytics,\n  IpDenyList,\n  MultiRegionRatelimit,\n  Ratelimit\n});\n//# sourceMappingURL=index.js.map","\"use strict\";var g=Object.defineProperty;var k=Object.getOwnPropertyDescriptor;var _=Object.getOwnPropertyNames;var y=Object.prototype.hasOwnProperty;var w=(l,e)=>{for(var t in e)g(l,t,{get:e[t],enumerable:!0})},A=(l,e,t,i)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let s of _(e))!y.call(l,s)&&s!==t&&g(l,s,{get:()=>e[s],enumerable:!(i=k(e,s))||i.enumerable});return l};var x=l=>A(g({},\"__esModule\",{value:!0}),l);var S={};w(S,{Analytics:()=>b});module.exports=x(S);var p=`\nlocal key = KEYS[1]\nlocal field = ARGV[1]\n\nlocal data = redis.call(\"ZRANGE\", key, 0, -1, \"WITHSCORES\")\nlocal count = {}\n\nfor i = 1, #data, 2 do\n  local json_str = data[i]\n  local score = tonumber(data[i + 1])\n  local obj = cjson.decode(json_str)\n\n  local fieldValue = obj[field]\n\n  if count[fieldValue] == nil then\n    count[fieldValue] = score\n  else\n    count[fieldValue] = count[fieldValue] + score\n  end\nend\n\nlocal result = {}\nfor k, v in pairs(count) do\n  table.insert(result, {k, v})\nend\n\nreturn result\n`,f=`\nlocal prefix = KEYS[1]\nlocal first_timestamp = tonumber(ARGV[1]) -- First timestamp to check\nlocal increment = tonumber(ARGV[2])       -- Increment between each timestamp\nlocal num_timestamps = tonumber(ARGV[3])  -- Number of timestampts to check (24 for a day and 24 * 7 for a week)\nlocal num_elements = tonumber(ARGV[4])    -- Number of elements to fetch in each category\nlocal check_at_most = tonumber(ARGV[5])   -- Number of elements to check at most.\n\nlocal keys = {}\nfor i = 1, num_timestamps do\n  local timestamp = first_timestamp - (i - 1) * increment\n  table.insert(keys, prefix .. \":\" .. timestamp)\nend\n\n-- get the union of the groups\nlocal zunion_params = {\"ZUNION\", num_timestamps, unpack(keys)}\ntable.insert(zunion_params, \"WITHSCORES\")\nlocal result = redis.call(unpack(zunion_params))\n\n-- select num_elements many items\nlocal true_group = {}\nlocal false_group = {}\nlocal denied_group = {}\nlocal true_count = 0\nlocal false_count = 0\nlocal denied_count = 0\nlocal i = #result - 1\n\n-- index to stop at after going through \"checkAtMost\" many items:\nlocal cutoff_index = #result - 2 * check_at_most\n\n-- iterate over the results\nwhile (true_count + false_count + denied_count) < (num_elements * 3) and 1 <= i and i >= cutoff_index do\n  local score = tonumber(result[i + 1])\n  if score > 0 then\n    local element = result[i]\n    if string.find(element, \"success\\\\\":true\") and true_count < num_elements then\n      table.insert(true_group, {score, element})\n      true_count = true_count + 1\n    elseif string.find(element, \"success\\\\\":false\") and false_count < num_elements then\n      table.insert(false_group, {score, element})\n      false_count = false_count + 1\n    elseif string.find(element, \"success\\\\\":\\\\\"denied\") and denied_count < num_elements then\n      table.insert(denied_group, {score, element})\n      denied_count = denied_count + 1\n    end\n  end\n  i = i - 2\nend\n\nreturn {true_group, false_group, denied_group}\n`,h=`\nlocal prefix = KEYS[1]\nlocal first_timestamp = tonumber(ARGV[1])\nlocal increment = tonumber(ARGV[2])\nlocal num_timestamps = tonumber(ARGV[3])\n\nlocal keys = {}\nfor i = 1, num_timestamps do\n  local timestamp = first_timestamp - (i - 1) * increment\n  table.insert(keys, prefix .. \":\" .. timestamp)\nend\n\n-- get the union of the groups\nlocal zunion_params = {\"ZUNION\", num_timestamps, unpack(keys)}\ntable.insert(zunion_params, \"WITHSCORES\")\nlocal result = redis.call(unpack(zunion_params))\n\nreturn result\n`;var b=class{redis;prefix;bucketSize;constructor(e){this.redis=e.redis,this.prefix=e.prefix??\"@upstash/analytics\",this.bucketSize=this.parseWindow(e.window)}validateTableName(e){if(!/^[a-zA-Z0-9_-]+$/.test(e))throw new Error(`Invalid table name: ${e}. Table names can only contain letters, numbers, dashes and underscores.`)}parseWindow(e){if(typeof e==\"number\"){if(e<=0)throw new Error(`Invalid window: ${e}`);return e}let t=/^(\\d+)([smhd])$/;if(!t.test(e))throw new Error(`Invalid window: ${e}`);let[,i,s]=e.match(t),n=parseInt(i);switch(s){case\"s\":return n*1e3;case\"m\":return n*1e3*60;case\"h\":return n*1e3*60*60;case\"d\":return n*1e3*60*60*24;default:throw new Error(`Invalid window unit: ${s}`)}}getBucket(e){let t=e??Date.now();return Math.floor(t/this.bucketSize)*this.bucketSize}async ingest(e,...t){this.validateTableName(e),await Promise.all(t.map(async i=>{let s=this.getBucket(i.time),n=[this.prefix,e,s].join(\":\");await this.redis.zincrby(n,1,JSON.stringify({...i,time:void 0}))}))}formatBucketAggregate(e,t,i){let s={};return e.forEach(([n,r])=>{t==\"success\"&&(n=n===1?\"true\":n===null?\"false\":n),s[t]=s[t]||{},s[t][(n??\"null\").toString()]=r}),{time:i,...s}}async aggregateBucket(e,t,i){this.validateTableName(e);let s=this.getBucket(i),n=[this.prefix,e,s].join(\":\"),r=await this.redis.eval(p,[n],[t]);return this.formatBucketAggregate(r,t,s)}async aggregateBuckets(e,t,i,s){this.validateTableName(e);let n=this.getBucket(s),r=[];for(let o=0;o<i;o+=1)r.push(this.aggregateBucket(e,t,n)),n=n-this.bucketSize;return Promise.all(r)}async aggregateBucketsWithPipeline(e,t,i,s,n){this.validateTableName(e),n=n??48;let r=this.getBucket(s),o=[],c=this.redis.pipeline(),u=[];for(let a=1;a<=i;a+=1){let d=[this.prefix,e,r].join(\":\");c.eval(p,[d],[t]),o.push(r),r=r-this.bucketSize,(a%n==0||a==i)&&(u.push(c.exec()),c=this.redis.pipeline())}return(await Promise.all(u)).flat().map((a,d)=>this.formatBucketAggregate(a,t,o[d]))}async getAllowedBlocked(e,t,i){this.validateTableName(e);let s=[this.prefix,e].join(\":\"),n=this.getBucket(i),r=await this.redis.eval(h,[s],[n,this.bucketSize,t]),o={};for(let c=0;c<r.length;c+=2){let u=r[c],m=u.identifier,a=+r[c+1];o[m]||(o[m]={success:0,blocked:0}),o[m][u.success?\"success\":\"blocked\"]=a}return o}async getMostAllowedBlocked(e,t,i,s,n){this.validateTableName(e);let r=[this.prefix,e].join(\":\"),o=this.getBucket(s),c=n??i*5,[u,m,a]=await this.redis.eval(f,[r],[o,this.bucketSize,t,i,c]);return{allowed:this.toDicts(u),ratelimited:this.toDicts(m),denied:this.toDicts(a)}}toDicts(e){let t=[];for(let i=0;i<e.length;i+=1){let s=+e[i][0],n=e[i][1];t.push({identifier:n.identifier,count:s})}return t}};0&&(module.exports={Analytics});\n"],"names":[],"sourceRoot":""}