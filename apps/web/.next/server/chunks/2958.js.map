{"version":3,"file":"2958.js","mappings":"ufAyHA,cACA,UACA,WACA,YACA,cACA,mBACA,cACA,kBACA,kBACA,SACA,eACA,CACA,CAKA,MAA6B,IAAQ,EACrC,OAAU,IAAS,UACnB,QAAW,IAAQ,GACnB,KAAQ,IAAQ,GAChB,MAAS,IAAQ,cACjB,KAAQ,IAAQ,aAChB,CAAC,EACD,EAAmC,QAA8B,EACjE,cACA,4BACC,EAGD,YACA,KACA,QACA,UACC,EACD,OACA,oBACA,yBACA,wCACA,CACA,CAyDA,YACA,mBACA,+BACA,wCACA,0BACA,eACA,gBACA,aACA,CACA,eACA,4BAEA,eACA,4BAEA,SACA,OACA,SACA,YACA,cACA,OACA,OACA,mBACA,kBACA,gBACA,iBACA,OACA,mBACG,EACH,QACA,aACA,WACA,GACA,QACA,2BACA,cACA,CAAO,EAEP,SACA,QACA,2BACA,0BACA,CAAO,EAEP,SACA,QACA,2BACA,yBACA,CAAO,EAEP,SACA,QACA,2BACA,uBACA,CAAO,EAEP,0CACA,QACA,2BACA,yBACA,sDACA,CAAO,EAEP,OAEA,mBAEA,qCAEA,aACA,cACA,QACA,cAEA,kDAA8F,oBAAsB,OAEpH,oFACA,kFAEA,SArRA,YACA,SACA,YAAkB,WAAmB,KACrC,SAAY,aAAgB,KAC5B,iBACA,UACA,aACA,QAAwB,wBAAyB,EACjD,KAEA,YACA,QACA,YACA,kBACA,MACA,eACA,WACA,OAAyB,wBAEzB,aACA,OACA,iBACA,4DAAyF,qCAAkD,SAAS,QAAyB,UAAa,EAG1L,YACA,4BACA,UAA4B,IAA6B,EACzD,mDACA,CAAmB,EAEnB,GACA,oBADA,WAEA,OACA,oBACA,8BACA,CAGA,WAA8B,IAA6B,EAC3D,6DACA,CAAqB,CAIrB,CACA,CAAW,CACX,CAAS,EACT,KAEA,kBACA,SACA,KACA,eACA,eACA,WACA,UACA,KAEA,iBACA,QACA,gBACA,gBACA,UACA,gBACA,gCACA,CACA,CAAe,CAGf,CAEA,QACA,iBACA,UACA,mBACA,8BACA,CAAS,EACT,KACA,CACA,WACA,eACA,QACA,YACA,gBACA,iCACA,0BACW,EAEX,KAEA,SAEA,iCADA,EAC8D,EAE9D,CACA,CACA,QACA,EAmLA,EACA,EACA,UACA,eACA,UAAgB,gCAtIhB,YACA,MACA,yDACA,KACA,WACA,OAAa,gDAEb,SACA,eACA,4BACA,QAA0B,+BAAgC,EAE1D,QACA,gBACA,UACA,YACA,0BACA,wBAEA,CAAO,EAGP,mBACA,WACA,OAAa,2CAEb,aACA,UACA,WACA,WACA,OAAe,qCACf,gBACA,OAAe,yCACf,YACA,OACA,eACA,iCAEA,kBACA,cACA,CACA,SAEA,UAAgB,IAA8B,EAC9C,+CAAwD,EAAiB,EAClE,CAEP,CACA,EAsFmD,GACnD,OACA,MAAkB,2BAAiC,CACnD,qBAEA,CACA,kBACA,OACA,MACA,KACA,iBAA+B,mBAC/B,CAAW,CACX,UACA,CAEA,mBACA,OACA,MACA,KACA,kBACA,QAAsB,gCAAuC,EAClD,CACX,UACA,CAEA,SAEA,iCADA,EAC8D,EAE9D,CACA,CACA,oBACA,MACA,SAAY,cAAiB,gBAC7B,CACA,kBACA,QACA,WACA,CAAM,MAAQ,QAAa,EAC3B,OAAc,oBAAoB,mBAClC,QAAe,QAAc,kCAC7B,OACA,wBACA,0BAAiC,QAAyB,CAC1D,GAEA,0BACA,wBACK,EACL,CAAY,iBAAsC,EAClD,eACA,uBACA,gBAIA,MAHA,gEACA,8BAEA,CACA,OACA,2DACA,wBACA,gBACA,yBACA,0BACA,CAAO,EACP,gCACA,OACA,mCACA,2CACO,CACP,mBAAiB,gBAAwB,CACzC,aACA,UACA,MACA,CAAO,CACP,SAAiB,uBAA4B,CAC7C,cACA,UACA,CACA,CACA,kBACA,SAAY,cAAiB,gBAC7B,GAAmB,gBACnB,iBAAY,WAAmC,MAAQ,QAAa,EACpE,OAAc,oBAAoB,mBAClC,QAAe,QAAc,kCAC7B,OACA,wBACA,0BAAiC,QAAgC,CACjE,GAEA,0BACA,wBACK,EACL,CAAY,iBAAsC,EAClD,YACA,GACA,wBACA,6BAEA,IACA,KACA,OACA,qBACA,qBACA,eACA,0BACA,WAAmC,2BAAmC,CAGtE,KACA,cACA,OACA,WACA,yBACA,QACe,EAEf,eACA,IACA,mCACA,2CACA,EAEA,mBAIA,GAHA,wCACA,uBAEA,+BACA,OAEA,cACA,eACA,SACA,oBACA,kDACA,2BACA,OAEA,MACA,CACA,CAQA,GAPA,UACA,WACA,kBACA,2BACA,CAAe,EACf,MAEA,mBACA,0BACA,WACA,uBACA,wBACA,gBACA,yBACA,kCACA,CAAiB,EACjB,WACA,iBACA,wBACA,gBACA,yBACA,0BACiB,CAGjB,CAAW,CACX,SACA,WAAiC,qCAAqC,CACtE,CACA,CAAS,GAET,mBAAiB,gBAAwB,CACzC,aAAqB,UAA0B,CAC/C,SAAiB,uBAA4B,CAC7C,UACA,CACA,CACA,EACA,cACA,sBACA,SAEA,WACA,OAEA,SACA,gBACA,SAAY,GAAO,EACnB,UACA,WACA,eACA,KACA,iBACA,gBACA,KACA,SAEA,iCADA,EAC8D,EAE9D,CACA,CACA,iCACA,CACA,MAA2B,IAAQ,EACjC,IAAS,GACT,IAAQ,CACN,IAAqB,SACnB,IAAS,EACf,KAAc,IAAU,SACxB,KAAc,IAAS,EACvB,CAAO,EACD,IAAS,EACf,KAAc,IAAU,cACxB,UAAmB,IAAQ,EACjB,IAAS,GACT,IAAS,EACnB,IAAiB,IAAS,GAC1B,OAAoB,IAAS,aAC7B,CAAW,EACX,CACA,CAAO,EACD,IAAS,EACf,KAAc,IAAU,cACxB,cAAuB,IAAQ,CAAC,IAAS,GACzC,CAAO,EACP,GAEA,YACA,EAAgC,IAAS,EACzC,GAAM,IAAS,aACf,QAAW,IAAS,aACpB,MAAS,IAAS,aAClB,QAAW,IAAQ,CACf,IAAS,EACb,QAAe,IAAS,EACxB,KAAc,IAAU,cACxB,UACA,WAAoB,IAAQ,CAClB,IAAS,EACnB,GAAgB,IAAS,GACzB,SAAsB,IAAS,EAAG,KAAM,IAAS,aAAe,IAAS,GAAI,CAC7E,CAAW,GACX,SACA,CAAO,EACP,MAAa,IAAS,GACtB,cAAqB,IAAS,YAC9B,CAAK,GAEL,OAAU,IAAU,oBACpB,MAAS,IAAS,EAClB,cAAmB,IAAS,GAC5B,kBAAuB,IAAS,EAChC,CAAG,CACH,CAAC,EACD,EAA6B,IAAS,EACtC,GAAM,IAAS,aACf,QAAW,IAAS,aACpB,MAAS,IAAS,aAClB,QAAW,IAAQ,CACf,IAAS,EACb,MAAa,IAAS,EACtB,KAAc,IAAO,2BACrB,UACA,WAAoB,IAAQ,CAClB,IAAS,EACnB,GAAgB,IAAS,GACzB,SAAsB,IAAS,EAAG,KAAM,IAAS,aAAe,IAAS,GAAI,CAC7E,CAAW,GACX,SACA,CAAO,EACP,cAAqB,IAAS,aAC9B,MAAa,IAAS,EACtB,CAAK,GAEL,MAAS,IAAS,EAClB,cAAmB,IAAS,GAC5B,kBAAuB,IAAS,EAChC,CAAG,WACH,CAAC,EAYD,QACA,mBACA,+BACA,eACA,gBACA,aACA,CACA,eACA,4BAEA,2BACA,MACA,wDACA,CACA,4BACA,MACA,uDACA,CACA,eACA,SACA,cACA,UACG,EACH,sCACA,UAAgB,IAAkC,EAClD,uBACA,qBACA,+CACA,QACA,CAAO,EAEP,oBAAY,WAAmC,MAAQ,QAAc,EACrE,OAAc,oBAAoB,aAClC,QAAe,QAAe,0BAC9B,MACA,mBACA,QACA,uBACA,CAAO,CACP,wBACA,0BAAiC,QAA0B,CAC3D,GAEA,cACA,wBACK,EACL,OACA,sCACA,eAAgC,8BAAuC,OACvE,aAAqB,UACrB,CACA,CACA,EACA,EAAyC,IAAS,EAClD,KAAQ,IAAQ,CAAC,IAAS,EAAG,UAAW,IAAQ,CAAC,IAAS,IAAK,GAC/D,MAAS,IAAS,EAAG,cAAe,IAAS,GAAI,WACjD,CAAC,EAyCD,EAtCA,aAAmC,EACnC,MACA,eAAwB,QAAoB,2CAC5C,QACA,wBAA6B,QAAU,EACvC,gBACA,0CACA,qBACA,CAAK,EAAE,EACP,aACA,CAAG,CACH,SAAiD,cACjD,wBACA,UACA,UACA,cACG,EACH,SAAsD,cACtD,6BACA,UACA,UACA,cACG,EACH,gBACA,cACA,YACA,qEAGA,aACA,EAMA,OALA,kBACA,SACA,cACA,kBACA,uBACA,CACA,sCC/qBA,UAOA,OALA,WACA,0DACA,gBACA,iBAIA,IACA,EACA,OACA,sBACA,WACA,iBAEA,6BAEM,qBACN,EAEA,uBAEA,EAAG,WACH,MACA,qBACA,EACM,iBACN,MAEA,OAEG,iBACH,2BACA,gBACA,sBACA,CACA,sCAIA,GAHA,GACA,mCAEA,gBACA,2BAEA,SADA,GAGA,SAEA,CAOA,GANA,eACA,6CAEA,yBACA,6DAEA,0BACA,gBACA,gDAEA,qCACA,WACA,8CAEA,qBACA,eACA,oDACA,IACA,sBAEA,CAOA,OANA,YACA,8CACA,+DAEA,uCACA,qCACA,mBACA,sBACA,WACA,uBACA,CAAO,CACP,CACA,SACA,CACA,oCCpFA,YACA","sources":["webpack://@hijraah/web/../../node_modules/.pnpm/@ai-sdk+mistral@1.2.8_zod@3.25.72/node_modules/@ai-sdk/mistral/dist/index.mjs","webpack://@hijraah/web/../../node_modules/.pnpm/hono@4.8.2/node_modules/hono/dist/middleware/cors/index.js","webpack://@hijraah/web/../../node_modules/.pnpm/hono@4.8.2/node_modules/hono/dist/adapter/vercel/handler.js"],"sourcesContent":["// src/mistral-provider.ts\nimport {\n  loadApiKey,\n  withoutTrailingSlash\n} from \"@ai-sdk/provider-utils\";\n\n// src/mistral-chat-language-model.ts\nimport {\n  combineHeaders,\n  createEventSourceResponseHandler,\n  createJsonResponseHandler,\n  postJsonToApi\n} from \"@ai-sdk/provider-utils\";\nimport { z as z2 } from \"zod\";\n\n// src/convert-to-mistral-chat-messages.ts\nimport {\n  UnsupportedFunctionalityError\n} from \"@ai-sdk/provider\";\nimport { convertUint8ArrayToBase64 } from \"@ai-sdk/provider-utils\";\nfunction convertToMistralChatMessages(prompt) {\n  const messages = [];\n  for (let i = 0; i < prompt.length; i++) {\n    const { role, content } = prompt[i];\n    const isLastMessage = i === prompt.length - 1;\n    switch (role) {\n      case \"system\": {\n        messages.push({ role: \"system\", content });\n        break;\n      }\n      case \"user\": {\n        messages.push({\n          role: \"user\",\n          content: content.map((part) => {\n            var _a;\n            switch (part.type) {\n              case \"text\": {\n                return { type: \"text\", text: part.text };\n              }\n              case \"image\": {\n                return {\n                  type: \"image_url\",\n                  image_url: part.image instanceof URL ? part.image.toString() : `data:${(_a = part.mimeType) != null ? _a : \"image/jpeg\"};base64,${convertUint8ArrayToBase64(part.image)}`\n                };\n              }\n              case \"file\": {\n                if (!(part.data instanceof URL)) {\n                  throw new UnsupportedFunctionalityError({\n                    functionality: \"File content parts in user messages\"\n                  });\n                }\n                switch (part.mimeType) {\n                  case \"application/pdf\": {\n                    return {\n                      type: \"document_url\",\n                      document_url: part.data.toString()\n                    };\n                  }\n                  default: {\n                    throw new UnsupportedFunctionalityError({\n                      functionality: \"Only PDF files are supported in user messages\"\n                    });\n                  }\n                }\n              }\n            }\n          })\n        });\n        break;\n      }\n      case \"assistant\": {\n        let text = \"\";\n        const toolCalls = [];\n        for (const part of content) {\n          switch (part.type) {\n            case \"text\": {\n              text += part.text;\n              break;\n            }\n            case \"tool-call\": {\n              toolCalls.push({\n                id: part.toolCallId,\n                type: \"function\",\n                function: {\n                  name: part.toolName,\n                  arguments: JSON.stringify(part.args)\n                }\n              });\n              break;\n            }\n          }\n        }\n        messages.push({\n          role: \"assistant\",\n          content: text,\n          prefix: isLastMessage ? true : void 0,\n          tool_calls: toolCalls.length > 0 ? toolCalls : void 0\n        });\n        break;\n      }\n      case \"tool\": {\n        for (const toolResponse of content) {\n          messages.push({\n            role: \"tool\",\n            name: toolResponse.toolName,\n            content: JSON.stringify(toolResponse.result),\n            tool_call_id: toolResponse.toolCallId\n          });\n        }\n        break;\n      }\n      default: {\n        const _exhaustiveCheck = role;\n        throw new Error(`Unsupported role: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n  return messages;\n}\n\n// src/map-mistral-finish-reason.ts\nfunction mapMistralFinishReason(finishReason) {\n  switch (finishReason) {\n    case \"stop\":\n      return \"stop\";\n    case \"length\":\n    case \"model_length\":\n      return \"length\";\n    case \"tool_calls\":\n      return \"tool-calls\";\n    default:\n      return \"unknown\";\n  }\n}\n\n// src/mistral-error.ts\nimport { createJsonErrorResponseHandler } from \"@ai-sdk/provider-utils\";\nimport { z } from \"zod\";\nvar mistralErrorDataSchema = z.object({\n  object: z.literal(\"error\"),\n  message: z.string(),\n  type: z.string(),\n  param: z.string().nullable(),\n  code: z.string().nullable()\n});\nvar mistralFailedResponseHandler = createJsonErrorResponseHandler({\n  errorSchema: mistralErrorDataSchema,\n  errorToMessage: (data) => data.message\n});\n\n// src/get-response-metadata.ts\nfunction getResponseMetadata({\n  id,\n  model,\n  created\n}) {\n  return {\n    id: id != null ? id : void 0,\n    modelId: model != null ? model : void 0,\n    timestamp: created != null ? new Date(created * 1e3) : void 0\n  };\n}\n\n// src/mistral-prepare-tools.ts\nimport {\n  UnsupportedFunctionalityError as UnsupportedFunctionalityError2\n} from \"@ai-sdk/provider\";\nfunction prepareTools(mode) {\n  var _a;\n  const tools = ((_a = mode.tools) == null ? void 0 : _a.length) ? mode.tools : void 0;\n  const toolWarnings = [];\n  if (tools == null) {\n    return { tools: void 0, tool_choice: void 0, toolWarnings };\n  }\n  const mistralTools = [];\n  for (const tool of tools) {\n    if (tool.type === \"provider-defined\") {\n      toolWarnings.push({ type: \"unsupported-tool\", tool });\n    } else {\n      mistralTools.push({\n        type: \"function\",\n        function: {\n          name: tool.name,\n          description: tool.description,\n          parameters: tool.parameters\n        }\n      });\n    }\n  }\n  const toolChoice = mode.toolChoice;\n  if (toolChoice == null) {\n    return { tools: mistralTools, tool_choice: void 0, toolWarnings };\n  }\n  const type = toolChoice.type;\n  switch (type) {\n    case \"auto\":\n    case \"none\":\n      return { tools: mistralTools, tool_choice: type, toolWarnings };\n    case \"required\":\n      return { tools: mistralTools, tool_choice: \"any\", toolWarnings };\n    case \"tool\":\n      return {\n        tools: mistralTools.filter(\n          (tool) => tool.function.name === toolChoice.toolName\n        ),\n        tool_choice: \"any\",\n        toolWarnings\n      };\n    default: {\n      const _exhaustiveCheck = type;\n      throw new UnsupportedFunctionalityError2({\n        functionality: `Unsupported tool choice type: ${_exhaustiveCheck}`\n      });\n    }\n  }\n}\n\n// src/mistral-chat-language-model.ts\nvar MistralChatLanguageModel = class {\n  constructor(modelId, settings, config) {\n    this.specificationVersion = \"v1\";\n    this.defaultObjectGenerationMode = \"json\";\n    this.supportsImageUrls = false;\n    this.modelId = modelId;\n    this.settings = settings;\n    this.config = config;\n  }\n  get provider() {\n    return this.config.provider;\n  }\n  supportsUrl(url) {\n    return url.protocol === \"https:\";\n  }\n  getArgs({\n    mode,\n    prompt,\n    maxTokens,\n    temperature,\n    topP,\n    topK,\n    frequencyPenalty,\n    presencePenalty,\n    stopSequences,\n    responseFormat,\n    seed,\n    providerMetadata\n  }) {\n    var _a, _b;\n    const type = mode.type;\n    const warnings = [];\n    if (topK != null) {\n      warnings.push({\n        type: \"unsupported-setting\",\n        setting: \"topK\"\n      });\n    }\n    if (frequencyPenalty != null) {\n      warnings.push({\n        type: \"unsupported-setting\",\n        setting: \"frequencyPenalty\"\n      });\n    }\n    if (presencePenalty != null) {\n      warnings.push({\n        type: \"unsupported-setting\",\n        setting: \"presencePenalty\"\n      });\n    }\n    if (stopSequences != null) {\n      warnings.push({\n        type: \"unsupported-setting\",\n        setting: \"stopSequences\"\n      });\n    }\n    if (responseFormat != null && responseFormat.type === \"json\" && responseFormat.schema != null) {\n      warnings.push({\n        type: \"unsupported-setting\",\n        setting: \"responseFormat\",\n        details: \"JSON response format schema is not supported\"\n      });\n    }\n    const baseArgs = {\n      // model id:\n      model: this.modelId,\n      // model specific settings:\n      safe_prompt: this.settings.safePrompt,\n      // standardized settings:\n      max_tokens: maxTokens,\n      temperature,\n      top_p: topP,\n      random_seed: seed,\n      // response format:\n      response_format: (responseFormat == null ? void 0 : responseFormat.type) === \"json\" ? { type: \"json_object\" } : void 0,\n      // mistral-specific provider options:\n      document_image_limit: (_a = providerMetadata == null ? void 0 : providerMetadata.mistral) == null ? void 0 : _a.documentImageLimit,\n      document_page_limit: (_b = providerMetadata == null ? void 0 : providerMetadata.mistral) == null ? void 0 : _b.documentPageLimit,\n      // messages:\n      messages: convertToMistralChatMessages(prompt)\n    };\n    switch (type) {\n      case \"regular\": {\n        const { tools, tool_choice, toolWarnings } = prepareTools(mode);\n        return {\n          args: { ...baseArgs, tools, tool_choice },\n          warnings: [...warnings, ...toolWarnings]\n        };\n      }\n      case \"object-json\": {\n        return {\n          args: {\n            ...baseArgs,\n            response_format: { type: \"json_object\" }\n          },\n          warnings\n        };\n      }\n      case \"object-tool\": {\n        return {\n          args: {\n            ...baseArgs,\n            tool_choice: \"any\",\n            tools: [{ type: \"function\", function: mode.tool }]\n          },\n          warnings\n        };\n      }\n      default: {\n        const _exhaustiveCheck = type;\n        throw new Error(`Unsupported type: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n  async doGenerate(options) {\n    var _a;\n    const { args, warnings } = this.getArgs(options);\n    const {\n      responseHeaders,\n      value: response,\n      rawValue: rawResponse\n    } = await postJsonToApi({\n      url: `${this.config.baseURL}/chat/completions`,\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body: args,\n      failedResponseHandler: mistralFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        mistralChatResponseSchema\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch\n    });\n    const { messages: rawPrompt, ...rawSettings } = args;\n    const choice = response.choices[0];\n    let text = extractTextContent(choice.message.content);\n    const lastMessage = rawPrompt[rawPrompt.length - 1];\n    if (lastMessage.role === \"assistant\" && (text == null ? void 0 : text.startsWith(lastMessage.content))) {\n      text = text.slice(lastMessage.content.length);\n    }\n    return {\n      text,\n      toolCalls: (_a = choice.message.tool_calls) == null ? void 0 : _a.map((toolCall) => ({\n        toolCallType: \"function\",\n        toolCallId: toolCall.id,\n        toolName: toolCall.function.name,\n        args: toolCall.function.arguments\n      })),\n      finishReason: mapMistralFinishReason(choice.finish_reason),\n      usage: {\n        promptTokens: response.usage.prompt_tokens,\n        completionTokens: response.usage.completion_tokens\n      },\n      rawCall: { rawPrompt, rawSettings },\n      rawResponse: {\n        headers: responseHeaders,\n        body: rawResponse\n      },\n      request: { body: JSON.stringify(args) },\n      response: getResponseMetadata(response),\n      warnings\n    };\n  }\n  async doStream(options) {\n    const { args, warnings } = this.getArgs(options);\n    const body = { ...args, stream: true };\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: `${this.config.baseURL}/chat/completions`,\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body,\n      failedResponseHandler: mistralFailedResponseHandler,\n      successfulResponseHandler: createEventSourceResponseHandler(\n        mistralChatChunkSchema\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch\n    });\n    const { messages: rawPrompt, ...rawSettings } = args;\n    let finishReason = \"unknown\";\n    let usage = {\n      promptTokens: Number.NaN,\n      completionTokens: Number.NaN\n    };\n    let chunkNumber = 0;\n    let trimLeadingSpace = false;\n    return {\n      stream: response.pipeThrough(\n        new TransformStream({\n          transform(chunk, controller) {\n            if (!chunk.success) {\n              controller.enqueue({ type: \"error\", error: chunk.error });\n              return;\n            }\n            chunkNumber++;\n            const value = chunk.value;\n            if (chunkNumber === 1) {\n              controller.enqueue({\n                type: \"response-metadata\",\n                ...getResponseMetadata(value)\n              });\n            }\n            if (value.usage != null) {\n              usage = {\n                promptTokens: value.usage.prompt_tokens,\n                completionTokens: value.usage.completion_tokens\n              };\n            }\n            const choice = value.choices[0];\n            if ((choice == null ? void 0 : choice.finish_reason) != null) {\n              finishReason = mapMistralFinishReason(choice.finish_reason);\n            }\n            if ((choice == null ? void 0 : choice.delta) == null) {\n              return;\n            }\n            const delta = choice.delta;\n            const textContent = extractTextContent(delta.content);\n            if (chunkNumber <= 2) {\n              const lastMessage = rawPrompt[rawPrompt.length - 1];\n              if (lastMessage.role === \"assistant\" && textContent === lastMessage.content.trimEnd()) {\n                if (textContent.length < lastMessage.content.length) {\n                  trimLeadingSpace = true;\n                }\n                return;\n              }\n            }\n            if (textContent != null) {\n              controller.enqueue({\n                type: \"text-delta\",\n                textDelta: trimLeadingSpace ? textContent.trimStart() : textContent\n              });\n              trimLeadingSpace = false;\n            }\n            if (delta.tool_calls != null) {\n              for (const toolCall of delta.tool_calls) {\n                controller.enqueue({\n                  type: \"tool-call-delta\",\n                  toolCallType: \"function\",\n                  toolCallId: toolCall.id,\n                  toolName: toolCall.function.name,\n                  argsTextDelta: toolCall.function.arguments\n                });\n                controller.enqueue({\n                  type: \"tool-call\",\n                  toolCallType: \"function\",\n                  toolCallId: toolCall.id,\n                  toolName: toolCall.function.name,\n                  args: toolCall.function.arguments\n                });\n              }\n            }\n          },\n          flush(controller) {\n            controller.enqueue({ type: \"finish\", finishReason, usage });\n          }\n        })\n      ),\n      rawCall: { rawPrompt, rawSettings },\n      rawResponse: { headers: responseHeaders },\n      request: { body: JSON.stringify(body) },\n      warnings\n    };\n  }\n};\nfunction extractTextContent(content) {\n  if (typeof content === \"string\") {\n    return content;\n  }\n  if (content == null) {\n    return void 0;\n  }\n  const textContent = [];\n  for (const chunk of content) {\n    const { type } = chunk;\n    switch (type) {\n      case \"text\":\n        textContent.push(chunk.text);\n        break;\n      case \"image_url\":\n      case \"reference\":\n        break;\n      default: {\n        const _exhaustiveCheck = type;\n        throw new Error(`Unsupported type: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n  return textContent.length ? textContent.join(\"\") : void 0;\n}\nvar mistralContentSchema = z2.union([\n  z2.string(),\n  z2.array(\n    z2.discriminatedUnion(\"type\", [\n      z2.object({\n        type: z2.literal(\"text\"),\n        text: z2.string()\n      }),\n      z2.object({\n        type: z2.literal(\"image_url\"),\n        image_url: z2.union([\n          z2.string(),\n          z2.object({\n            url: z2.string(),\n            detail: z2.string().nullable()\n          })\n        ])\n      }),\n      z2.object({\n        type: z2.literal(\"reference\"),\n        reference_ids: z2.array(z2.number())\n      })\n    ])\n  )\n]).nullish();\nvar mistralChatResponseSchema = z2.object({\n  id: z2.string().nullish(),\n  created: z2.number().nullish(),\n  model: z2.string().nullish(),\n  choices: z2.array(\n    z2.object({\n      message: z2.object({\n        role: z2.literal(\"assistant\"),\n        content: mistralContentSchema,\n        tool_calls: z2.array(\n          z2.object({\n            id: z2.string(),\n            function: z2.object({ name: z2.string(), arguments: z2.string() })\n          })\n        ).nullish()\n      }),\n      index: z2.number(),\n      finish_reason: z2.string().nullish()\n    })\n  ),\n  object: z2.literal(\"chat.completion\"),\n  usage: z2.object({\n    prompt_tokens: z2.number(),\n    completion_tokens: z2.number()\n  })\n});\nvar mistralChatChunkSchema = z2.object({\n  id: z2.string().nullish(),\n  created: z2.number().nullish(),\n  model: z2.string().nullish(),\n  choices: z2.array(\n    z2.object({\n      delta: z2.object({\n        role: z2.enum([\"assistant\"]).optional(),\n        content: mistralContentSchema,\n        tool_calls: z2.array(\n          z2.object({\n            id: z2.string(),\n            function: z2.object({ name: z2.string(), arguments: z2.string() })\n          })\n        ).nullish()\n      }),\n      finish_reason: z2.string().nullish(),\n      index: z2.number()\n    })\n  ),\n  usage: z2.object({\n    prompt_tokens: z2.number(),\n    completion_tokens: z2.number()\n  }).nullish()\n});\n\n// src/mistral-embedding-model.ts\nimport {\n  TooManyEmbeddingValuesForCallError\n} from \"@ai-sdk/provider\";\nimport {\n  combineHeaders as combineHeaders2,\n  createJsonResponseHandler as createJsonResponseHandler2,\n  postJsonToApi as postJsonToApi2\n} from \"@ai-sdk/provider-utils\";\nimport { z as z3 } from \"zod\";\nvar MistralEmbeddingModel = class {\n  constructor(modelId, settings, config) {\n    this.specificationVersion = \"v1\";\n    this.modelId = modelId;\n    this.settings = settings;\n    this.config = config;\n  }\n  get provider() {\n    return this.config.provider;\n  }\n  get maxEmbeddingsPerCall() {\n    var _a;\n    return (_a = this.settings.maxEmbeddingsPerCall) != null ? _a : 32;\n  }\n  get supportsParallelCalls() {\n    var _a;\n    return (_a = this.settings.supportsParallelCalls) != null ? _a : false;\n  }\n  async doEmbed({\n    values,\n    abortSignal,\n    headers\n  }) {\n    if (values.length > this.maxEmbeddingsPerCall) {\n      throw new TooManyEmbeddingValuesForCallError({\n        provider: this.provider,\n        modelId: this.modelId,\n        maxEmbeddingsPerCall: this.maxEmbeddingsPerCall,\n        values\n      });\n    }\n    const { responseHeaders, value: response } = await postJsonToApi2({\n      url: `${this.config.baseURL}/embeddings`,\n      headers: combineHeaders2(this.config.headers(), headers),\n      body: {\n        model: this.modelId,\n        input: values,\n        encoding_format: \"float\"\n      },\n      failedResponseHandler: mistralFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler2(\n        MistralTextEmbeddingResponseSchema\n      ),\n      abortSignal,\n      fetch: this.config.fetch\n    });\n    return {\n      embeddings: response.data.map((item) => item.embedding),\n      usage: response.usage ? { tokens: response.usage.prompt_tokens } : void 0,\n      rawResponse: { headers: responseHeaders }\n    };\n  }\n};\nvar MistralTextEmbeddingResponseSchema = z3.object({\n  data: z3.array(z3.object({ embedding: z3.array(z3.number()) })),\n  usage: z3.object({ prompt_tokens: z3.number() }).nullish()\n});\n\n// src/mistral-provider.ts\nfunction createMistral(options = {}) {\n  var _a;\n  const baseURL = (_a = withoutTrailingSlash(options.baseURL)) != null ? _a : \"https://api.mistral.ai/v1\";\n  const getHeaders = () => ({\n    Authorization: `Bearer ${loadApiKey({\n      apiKey: options.apiKey,\n      environmentVariableName: \"MISTRAL_API_KEY\",\n      description: \"Mistral\"\n    })}`,\n    ...options.headers\n  });\n  const createChatModel = (modelId, settings = {}) => new MistralChatLanguageModel(modelId, settings, {\n    provider: \"mistral.chat\",\n    baseURL,\n    headers: getHeaders,\n    fetch: options.fetch\n  });\n  const createEmbeddingModel = (modelId, settings = {}) => new MistralEmbeddingModel(modelId, settings, {\n    provider: \"mistral.embedding\",\n    baseURL,\n    headers: getHeaders,\n    fetch: options.fetch\n  });\n  const provider = function(modelId, settings) {\n    if (new.target) {\n      throw new Error(\n        \"The Mistral model function cannot be called with the new keyword.\"\n      );\n    }\n    return createChatModel(modelId, settings);\n  };\n  provider.languageModel = createChatModel;\n  provider.chat = createChatModel;\n  provider.embedding = createEmbeddingModel;\n  provider.textEmbedding = createEmbeddingModel;\n  provider.textEmbeddingModel = createEmbeddingModel;\n  return provider;\n}\nvar mistral = createMistral();\nexport {\n  createMistral,\n  mistral\n};\n//# sourceMappingURL=index.mjs.map","// src/middleware/cors/index.ts\nvar cors = (options) => {\n  const defaults = {\n    origin: \"*\",\n    allowMethods: [\"GET\", \"HEAD\", \"PUT\", \"POST\", \"DELETE\", \"PATCH\"],\n    allowHeaders: [],\n    exposeHeaders: []\n  };\n  const opts = {\n    ...defaults,\n    ...options\n  };\n  const findAllowOrigin = ((optsOrigin) => {\n    if (typeof optsOrigin === \"string\") {\n      if (optsOrigin === \"*\") {\n        return () => optsOrigin;\n      } else {\n        return (origin) => optsOrigin === origin ? origin : null;\n      }\n    } else if (typeof optsOrigin === \"function\") {\n      return optsOrigin;\n    } else {\n      return (origin) => optsOrigin.includes(origin) ? origin : null;\n    }\n  })(opts.origin);\n  const findAllowMethods = ((optsAllowMethods) => {\n    if (typeof optsAllowMethods === \"function\") {\n      return optsAllowMethods;\n    } else if (Array.isArray(optsAllowMethods)) {\n      return () => optsAllowMethods;\n    } else {\n      return () => [];\n    }\n  })(opts.allowMethods);\n  return async function cors2(c, next) {\n    function set(key, value) {\n      c.res.headers.set(key, value);\n    }\n    const allowOrigin = findAllowOrigin(c.req.header(\"origin\") || \"\", c);\n    if (allowOrigin) {\n      set(\"Access-Control-Allow-Origin\", allowOrigin);\n    }\n    if (opts.origin !== \"*\") {\n      const existingVary = c.req.header(\"Vary\");\n      if (existingVary) {\n        set(\"Vary\", existingVary);\n      } else {\n        set(\"Vary\", \"Origin\");\n      }\n    }\n    if (opts.credentials) {\n      set(\"Access-Control-Allow-Credentials\", \"true\");\n    }\n    if (opts.exposeHeaders?.length) {\n      set(\"Access-Control-Expose-Headers\", opts.exposeHeaders.join(\",\"));\n    }\n    if (c.req.method === \"OPTIONS\") {\n      if (opts.maxAge != null) {\n        set(\"Access-Control-Max-Age\", opts.maxAge.toString());\n      }\n      const allowMethods = findAllowMethods(c.req.header(\"origin\") || \"\", c);\n      if (allowMethods.length) {\n        set(\"Access-Control-Allow-Methods\", allowMethods.join(\",\"));\n      }\n      let headers = opts.allowHeaders;\n      if (!headers?.length) {\n        const requestHeaders = c.req.header(\"Access-Control-Request-Headers\");\n        if (requestHeaders) {\n          headers = requestHeaders.split(/\\s*,\\s*/);\n        }\n      }\n      if (headers?.length) {\n        set(\"Access-Control-Allow-Headers\", headers.join(\",\"));\n        c.res.headers.append(\"Vary\", \"Access-Control-Request-Headers\");\n      }\n      c.res.headers.delete(\"Content-Length\");\n      c.res.headers.delete(\"Content-Type\");\n      return new Response(null, {\n        headers: c.res.headers,\n        status: 204,\n        statusText: \"No Content\"\n      });\n    }\n    await next();\n  };\n};\nexport {\n  cors\n};\n","// src/adapter/vercel/handler.ts\nvar handle = (app) => (req) => {\n  return app.fetch(req);\n};\nexport {\n  handle\n};\n"],"names":[],"sourceRoot":""}