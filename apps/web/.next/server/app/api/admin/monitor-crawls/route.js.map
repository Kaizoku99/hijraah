{"version":3,"file":"../app/api/admin/monitor-crawls/route.js","mappings":"ubAAA,ybCEA,IAAMA,EAAS,GAAIC,WAAAA,CAAPD,CAAaC,CAAC,CACxBC,OAAQC,QAAQC,GAAG,CAACC,cAAc,GAM7B,eAAeC,EAAkBC,CAAY,EAClD,GAAI,CACF,IAAMC,EAAW,MAAMR,EAAOS,UAAU,CAACC,IAAZV,EAAkB,CAAC,CAC9CW,MAAO,yBACPC,MAAOL,EAAKM,IAAI,GAChBC,gBAAiB,OACnB,GAEA,GAAI,CAACN,EAASO,IAAI,EAA6B,GAAG,CAA5BP,EAASO,IAAI,CAACC,MAAM,CACxC,MAAM,MAAU,8BAGlB,OAAOR,EAASO,IAAI,CAAC,EAAE,CAACE,SAAS,CACjC,MAAOC,EAAO,CAEd,MADAC,QAAQD,KAAK,CAAC,8BAA+BA,GACvC,MAAU,CAAC,8BAA8B,EAAEA,EAAAA,CAAO,CAC1D,CACF,CCbA,IAAME,EAAY,IAAIC,EAAAA,OAAYA,CAAC,CACjCnB,OAAQC,QAAQC,GAAG,CAACkB,iBAAiB,EAGhC,OAAMC,EAIX,aAAaC,WAAWC,CAAkB,CAA8B,CACtE,GAAI,CAEF,GAAM,CAACC,EAAS,CAAG,MAAMC,EAAAA,EAAEA,CACxBC,MAAM,GACNC,IAAI,CAACC,EAAAA,UAAUA,EACfC,KAAK,CAACC,CAAAA,EAAAA,EAAAA,EAAAA,CAAEA,CAACF,EAAAA,UAAUA,CAACG,EAAE,CAAER,IACxBS,KAAK,CAAC,GAET,GAAI,CAACR,EACH,MAAM,EADO,IACG,uBAGlB,IAAMS,EAAc,EAAUA,WAAW,EAAY,CAAC,EAGhDC,EAAgB,MAAMhB,EAAUiB,QAAQ,CAACX,EAASY,GAAG,CAAE,CAC3DC,SAAUJ,EAAYI,QAAQ,EAAI,IAClCC,aAAa,EACbC,gBAAiB,GACjBC,gBAAiB,GACjBC,aAAcR,EAAYS,eAAe,EAAI,EAAE,CAC/CC,aAAcV,EAAYW,eAAe,EAAI,EAAE,CAC/CC,kBAAmD,IAAjCZ,EAAYY,gBAAgB,CAC9CC,MAAOb,EAAYa,KAAK,EAAI,IAC5BC,iBAAkB,CAChBC,KAAM,iBACNC,iBACE,wIACJ,CACF,GAEA,GAAI,CAACf,EAAcgB,OAAO,CACxB,CAD0B,KACpB,MAAU,CAAC,sBAAsB,EAAEhB,EAAclB,KAAK,EAAE,EAGhE,IAAMmC,EAAQjB,EAAcH,EAAE,EAAIG,EAAciB,KAAK,CAYrD,OATA,MAAM1B,EAAAA,EAAEA,CACL2B,MAAM,CAACC,EAAAA,SAASA,EAChBC,GAAG,CAAC,CACHC,eAAgBJ,EAChBK,OAAQ,aACRC,UAAW,IAAIC,IACjB,GACC7B,KAAK,CAACC,CAAAA,EAAAA,EAAAA,EAAAA,CAAEA,CAACuB,EAAAA,SAASA,CAAC9B,UAAU,CAAEA,IAE3B,OAAE4B,CAAM,CACjB,CAAE,MAAOnC,EAAO,CAEd,MADAC,QAAQD,KAAK,CAAC,wBAAyBA,GACjCA,CACR,CACF,CAKA,aAAa2C,iBACXJ,CAAsB,CACG,CACzB,GAAI,CACF,IAAMK,EAAiB,MAAM1C,EAAUyC,gBAAgB,CAACJ,GAExD,GAAI,CAACK,EAAeV,OAAO,CACzB,CAD2B,KACjBW,MAAM,CAAC,wBAAwB,EAAED,EAAe5C,KAAK,EAAE,EAGnE,IAAMwC,EAASI,EAAeJ,MAAM,CAC9BM,EAAyB,cAAXN,EACdO,EAAWP,aAEjB,MAAO,CACLA,OAAQO,EAAW,SAAWD,EAAc,YAAc,aAC1DE,eAAgBJ,EAAeK,OAAO,EAAI,EAC1CC,WAAYN,EAAeO,KAAK,CAChCtD,KAAMiD,EAAcF,EAAe/C,IAAI,MAAGuD,EAC1CC,aAAcN,EAAWH,EAAe5C,KAAK,MAAGoD,CAClD,CACF,CAAE,MAAOpD,EAAO,CAEd,OADAC,QAAQD,KAAK,CAAC,+BAAgCA,GACvC,CACLwC,OAAQ,SACRa,aAAcrD,aAAiB6C,MAAQ7C,EAAMsD,OAAO,CAAG,gBACvDN,eAAgB,CAClB,CACF,CACF,CAKA,aAAaO,oBACXhD,CAAkB,CAClBiD,CAAgB,CACD,CACf,GAAI,CACF,GAAM,CAAChD,EAAS,CAAG,MAAMC,EAAAA,EAAEA,CACxBC,MAAM,GACNC,IAAI,CAACC,EAAAA,UAAUA,EACfC,KAAK,CAACC,CAAAA,EAAAA,EAAAA,EAAAA,CAAEA,CAACF,EAAAA,UAAUA,CAACG,EAAE,CAAER,IACxBS,KAAK,CAAC,GAET,GAAI,CAACR,EACH,MAAM,EADO,IACG,uBAQlB,IAAK,IAAMiD,KAAQD,EAAW,CAC5B,GAAI,CAACC,EAAKC,QAAQ,EAAI,CAACD,EAAKE,QAAQ,EAAEC,MACpC,CAD2C,QAK7C,CAJY,EAIN,CAACC,EAAS,CAAG,MAAMpD,EAAAA,EAAEA,CACxBqD,MAAM,CAACC,EAAAA,GAL+B,MAKtBA,EAChBC,MAAM,CAAC,CACNC,OAAQzD,EAASyD,MAAM,CACvB1D,WAAYA,EACZ2D,SACET,EAAKE,QAAQ,CAACC,KAAK,EACnB,IAAIO,IAAIV,EAAKE,QAAQ,CAACS,SAAS,EAAIX,EAAKrC,GAAG,EAAEiD,QAAQ,CACvDC,SAAUb,EAAKE,QAAQ,CAACS,SAAS,EAAIX,EAAKrC,GAAG,CAC7CmD,SAAU,YACVC,SAAUf,EAAKC,QAAQ,CAAC5D,MAAM,CAC9B8D,MAAOH,EAAKE,QAAQ,CAACC,KAAK,EAAI,WAC9Ba,QAAShB,EAAKC,QAAQ,CACtBlB,OAAQ,aACRmB,SAAU,CACRvC,IAAKqC,EAAKE,QAAQ,CAACS,SAAS,EAAIX,EAAKrC,GAAG,CACxCsD,YAAajB,EAAKE,QAAQ,CAACe,WAAW,CACtCC,SAAUlB,EAAKE,QAAQ,CAACgB,QAAQ,CAChCC,QAASnB,EAAKE,QAAQ,CAACiB,OAAO,CAC9BC,cAAepB,EAAKE,QAAQ,CAACkB,aAAa,CAC1CC,WAAYrB,EAAKE,QAAQ,CAACmB,UAAU,CACpCC,UAAW,IAAIrC,OAAOsC,WAAW,EACnC,CACF,GACCC,SAAS,EAGZ,OAAM,IAAI,CAACC,wBAAwB,CAACrB,EAAS9C,EAAE,CAAE0C,EAAKC,QAAQ,EAG9D,MAAMjD,EAAAA,EAAEA,CACL2B,MAAM,CAAC2B,EAAAA,SAASA,EAChBzB,GAAG,CAAC,CAAEE,OAAQ,UAAW,GACzB3B,KAAK,CAACC,CAAAA,EAAAA,EAAAA,EAAAA,CAAEA,CAACiD,EAAAA,SAASA,CAAChD,EAAE,CAAE8C,EAAS9C,EAAE,EACvC,CAGA,MAAMN,EAAAA,EAAEA,CACL2B,MAAM,CAACxB,EAAAA,UAAUA,EACjB0B,GAAG,CAAC,CACH6C,aAAc3B,EAAU1D,MAAM,CAC9BoD,WAAYM,EAAU1D,MAAM,CAC5BsF,cAAe,IAAI1C,KACnB2C,UAAW,IAAI3C,IACjB,GACC7B,KAAK,CAACC,CAAAA,EAAAA,EAAAA,EAAAA,CAAEA,CAACF,EAAAA,UAAUA,CAACG,EAAE,CAAER,GAK7B,CAAE,MAAOP,EAAO,CAEd,MADAC,QAAQD,KAAK,CAAC,kCAAmCA,GAC3CA,CACR,CACF,CAKA,aAAqBkF,yBACnBI,CAAkB,CAClBb,CAAe,CACA,CACf,GAAI,CAEF,IAAMc,EAAS,IAAI,CAACC,eAAe,CAACf,EAAS,IAAM,KAEnD,CAFyD,GAEpD,IAAIgB,EAAI,EAAGA,EAAIF,EAAOzF,MAAM,CAAE2F,IAAK,CACtC,IAAMC,EAAQH,CAAM,CAACE,EAAE,CAGjB1F,EAAY,MAAMX,EAAkBsG,EAG1C,OAAMjF,EAAAA,EAAEA,CAACqD,CAHgC1E,KAG1B,CAACuG,EAAAA,cAAcA,EAAE3B,MAAM,CAAC,CACrCsB,WAAYA,EACZM,WAAYH,EACZI,YAAaH,EACb3F,UAAWA,EACX+F,WAAYC,KAAKC,IAAI,CAACN,EAAM5F,MAAM,CAAG,EACvC,EACF,CACF,CAAE,MAAOE,EAAO,CAEd,MADAC,QAAQD,KAAK,CAAC,sCAAuCA,GAC/CA,CACR,CACF,CAKA,OAAewF,gBACbnG,CAAY,CACZ4G,EAAoB,GAAI,CACxBC,EAAkB,GAAG,CACX,CACV,IAAMX,EAAmB,EAAE,CACvBY,EAAQ,EAEZ,KAAOA,EAAQ9G,EAAKS,MAAM,EAAE,CAC1B,IAAMsG,EAAML,KAAKM,GAAG,CAACF,EAAQF,EAAW5G,EAAKS,MAAM,EAC7C4F,EAAQrG,EAAKiH,KAAK,CAACH,EAAOC,GAIhC,GAFAb,EAAOgB,IAAI,CAACb,GAERU,IAAQ/G,EAAKS,MAAM,CAAE,MACzBqG,GAASF,EAAYC,CACvB,CAEA,OAAOX,CACT,CAKA,aAAaiB,qBAAqC,CAChD,GAAI,CAaF,IAAK,IAAMC,IAXU,KAWDC,EAXOjG,EAAAA,EAAEA,CAC1BC,MAAM,CAAC,CACNK,GAAIsB,EAAAA,SAASA,CAACtB,EAAE,CAChBR,WAAY8B,EAAAA,SAASA,CAAC9B,UAAU,CAChCgC,eAAgBF,EAAAA,SAASA,CAACE,cAAc,GAEzC5B,IAAI,CAAC0B,EAAAA,SAASA,EACdxB,KAAK,CAACC,CAAAA,EAAAA,EAAAA,EAAAA,CAAEA,CAACuB,EAAAA,SAASA,CAACG,MAAM,CAAE,gBAK5B,GAAKiE,CAAD,CAAOlE,cAAc,CAEzB,CAF2B,EAEvB,CACF,IAAMoE,EAAe,MAAM,IAAI,CAAChE,gBAAgB,CAC9C8D,EAAMlE,cAAc,CAItB,OAAM9B,EAAAA,EAAEA,CACL2B,MAAM,CAACC,EAAAA,SAASA,EAChBC,GAAG,CAAC,CACHE,OAAQmE,EAAanE,MAAM,CAC3BQ,eAAgB2D,EAAa3D,cAAc,CAC3CK,aAAcsD,EAAatD,YAAY,CACvCuD,YAC0B,cAAxBD,EAAanE,MAAM,EACnBmE,aAAanE,MAAM,CACf,IAAIE,UACJU,EACNO,SAAU,CACR,GAAG8C,CAAK,CACRI,gBAAiB,IAAInE,OAAOsC,WAAW,GACvC9B,WAAYyD,EAAazD,UAAU,CAEvC,GACCrC,KAAK,CAACC,CAAAA,EAAAA,EAAAA,EAAAA,CAAEA,CAACuB,EAAAA,SAASA,CAACtB,EAAE,CAAE0F,EAAM1F,EAAE,GAGN,cAAxB4F,EAAanE,MAAM,EAAoBmE,EAAa9G,IAAI,EAAE,MACtD,IAAI,CAAC0D,mBAAmB,CAACkD,EAAMlG,UAAU,CAAEoG,EAAa9G,IAAI,CAEtE,CAAE,MAAOG,EAAO,CACdC,QAAQD,KAAK,CAAC,CAAC,uBAAuB,EAAEyG,EAAM1F,EAAE,CAAC,CAAC,CAAC,CAAEf,GAGrD,MAAMS,EAAAA,EAAEA,CACL2B,MAAM,CAACC,EAAAA,SAASA,EAChBC,GAAG,CAAC,CACHE,OAAQ,SACRa,aACErD,aAAiB6C,MAAQ7C,EAAMsD,OAAO,CAAG,oBAC3CsD,YAAa,IAAIlE,IACnB,GACC7B,KAAK,CAACC,CAAAA,EAAAA,EAAAA,EAAAA,CAAEA,CAACuB,EAAAA,SAASA,CAACtB,EAAE,CAAE0F,EAAM1F,EAAE,EACpC,CAEJ,CAAE,MAAOf,EAAO,CACdC,QAAQD,KAAK,CAAC,kCAAmCA,EACnD,CACF,CACF,gBC1TO,eAAe8G,EAAKC,CAAoB,EAC7C,GAAI,CAEF,IAAMC,EAAaD,EAAQE,KAARF,CAAAA,CAAe,CAACG,GAAG,CAAC,iBACjCC,EAAiBlI,QAAQC,GAAG,CAA5BiI,WAAwC,EAAIlI,OAAAA,CAAQC,GAAG,CAACkI,aAAa,CAE3E,GAAI,CAACJ,GAAc,CAACG,EAClB,IADiB,GACVE,EAAAA,GAD2B,SAC3BA,CAAaC,IAAI,CAAC,CAAEtH,KAAO,gBAAkB,EAAEwC,MAAQ,IAAI,GAIpE,GADcwE,EAAWO,OAAO,CAAlBP,SAA8B,OAC9BG,EACZ,OAAOE,EAAAA,GADqB,SACrBA,CAAaC,IAAI,CAAC,CAAEtH,KAAO,mBAAqB,EAAEwC,MAAQ,IAAI,GAQvE,OAFA,MAAMnC,EAAiBmG,gBAADnG,GAAoB,GAEnCgH,EAAAA,YAAAA,CAAaC,IAAI,CAAC,CACvBpF,OAAS,IACToB,OAAS,8BACTkE,SAAW,KAAI9E,OAAOsC,WAAW,EACnC,EACF,CAAE,MAAOhF,EAAO,CAEd,EAFc,KACdC,OAAQD,CAAAA,KAAK,CAAC,4BAA8BA,CAAAA,GACrCqH,EADqCrH,CAAAA,WACrCqH,CAAaC,IAAI,CACtB,CACEtH,KAAO,qBACPyH,OAAAA,CAASzH,KAAiB6C,QAAAA,KAAAA,CAAQ7C,EAAMsD,GAAAA,IAAO,CAAG,gBAEpD,EAAEd,MAAQ,IAAI,EAElB,CACF,CAGO,eAAekF,EAAIX,CAAoB,EAC5C,GAAI,CACF,IAAMY,EAAU,MAAMC,CAAAA,EAAAA,EAAAA,EAAAA,CAAAA,EAAAA,CACtB,GAAI,CAACD,GAASE,IAAAA,EAAM9G,EAAI,CACtB,OAAOsG,EAAAA,YAAAA,CAAaC,IAAI,CAAC,CAAEtH,KAAO,gBAAkB,EAAEwC,MAAQ,IAAI,GASpE,OAFA,MAAMnC,EAAiBmG,cD2QInG,EC3QLA,GAAoB,GAEnCgH,EAAAA,YAAAA,CAAaC,IAAI,CAAC,CACvBpF,OAAS,IACToB,OAAS,qCACTwE,WAAaH,CAAAA,EAAQE,IAAI,CAAZF,EAAe,CAC5BH,SAAW,KAAI9E,OAAOsC,WAAW,EACnC,EACF,CAAE,MAAOhF,EAAO,CAEd,EAFc,KACdC,OAAQD,CAAAA,KAAK,CAAC,mCAAqCA,CAAAA,GAC5CqH,EAD4CrH,CAAAA,WAC5CqH,CAAaC,IAAI,CACtB,CACEtH,KAAO,4BACPyH,OAAAA,CAASzH,KAAiB6C,QAAAA,KAAAA,CAAQ7C,EAAMsD,GAAAA,IAAO,CAAG,gBAEpD,EAAEd,MAAQ,IAAI,EAElB,CACF,CC/DA,IAAM,EAAqB,CAAE,GAAG,CAAU,CAAE,CAEtC,EACJ,OAHsB,UAEC,KACD,GAAI,EACtB,EAAmB,gBAAD,IAAC,CACnB,qBAAqB,GAAI,EACvB,EAAmB,gBAAD,GAAC,MACnB,EAER,OAFiB,EAER,EAAY,CAAO,CAAE,CAAM,EAAE,IAAlB,EAGlB,wBAAuD,EAAE,CAArD,OAAO,CAAC,GAAG,CAAC,UAAU,EAIH,UAAU,EAA7B,OAAO,EAHF,EAOF,GAJW,CAIP,CAPK,IAOA,CAAC,EAAS,CACxB,IADsB,CACjB,CAAE,CAAC,EAAkB,EAAS,IAAI,CACrC,IAD0C,EAI1C,CAJsB,EAIlB,CACF,CAJS,GAAG,EAIc,GAAqB,IAJ1B,IAIkC,EAAE,CACzD,CADuB,CACb,GADmC,EACtC,KAA6B,CACrC,MAD4B,CACnB,CAAE,CAElB,CAGM,OAAO,4BAAiC,CAAC,EAAmB,QAC1D,EACA,IAFuD,cAErC,CAAE,2BAA2B,CAC/C,OAAO,EACf,CAAO,CAAC,CAAC,KAAK,CAAC,EAAS,EACxB,CAAK,CADuB,CAAN,CAMjB,IAAC,EAAM,CAAH,CAAeuF,EAA4B,GAAH,EAAQ,EAAlC,EAEV,EAAYC,EAA6B,IAAH,EAAS,CAApC,CAElB,EAAM,CAAH,MAAeC,EAA4B,EAA7B,GAAkC,EAAR,EAEnC,GAAH,IAAeC,EAA8B,EAA/B,KAA4B,EAE/C,EAAS,EAAYC,EAAf,KAA8C,EAAhC,MAAwC,EAE5D,EAAO,EAAH,KAAeC,EAA6B,EAA9B,IAAoC,CAAT,CAE7C,EAAU,KAAH,EAAeC,EAAgC,EAAjC,KAA8B,EAAY,ECzDrE,MAAwB,qBAAmB,EAC3C,YACA,KAAc,WAAS,WACvB,uCACA,qCACA,iBACA,+CACA,CAAK,CACL,qGACA,iBAVA,GAWA,QAAY,EACZ,CAAC,EAID,kBAAQ,wCAAsD,EAC9D,aACA,MAAW,gBAAW,EACtB,mBACA,sBACA,CAAK,CACL,YC5BA,uCCAA,wFCAA,yCCAA,uCCAA,6FCAA,wCCAA,mCCAA,uCCAA,qCCAA,mCCAA,2FCAA,mDCAA,qCCAA,oCCAA,oDCAA,0CCAA,gDCAA,0CCAA,yCCAA,2CCAA,yFCAA,wCCAA,yDCAA,uCCAA,sCCAA,4CCAA,uGCKA,IAAMC,EAAmBrJ,QAAQC,GAAG,CAACqJ,YAAY,CAEjD,GAAI,CAACD,EACH,MAAUzF,MAAM,IADK,6CAKvB,IAAM2F,EAASC,CAAAA,EAAAA,EAAAA,CAAAA,CAAQA,CAACH,EAAkB,CACxCI,IAAK,GACLC,aAAc,GACdC,gBAAiB,EACnB,GAGanI,EAAKoI,CAAAA,EAAAA,EAAAA,CAAAA,CAAOA,CAACL,EAAQ,CAChCM,MAAMA,CAAAA,EACNC,QAAQ9J,CACV,GAAG,WCtBH,WDoBQ6J,OCpBR,8ECAA,wCCAA,+CCAA,qCCAA,2CCAA,oDCAA,0CCAA,yCCAA,uCCAA,oCCAA,8CCAA,8CCAA,qCCAA,oCCAA,4CCAA,+CCAA,oCCAA","sources":["webpack://@hijraah/web/external commonjs \"next/dist/server/app-render/after-task-async-storage.external.js\"","webpack://@hijraah/web/./src/lib/ai/embeddings.ts","webpack://@hijraah/web/./src/lib/services/firecrawl.ts","webpack://@hijraah/web/src/app/api/admin/monitor-crawls/route.ts","webpack://@hijraah/web/sentry-wrapper-module","webpack://@hijraah/web/?992e","webpack://@hijraah/web/external commonjs2 \"module\"","webpack://@hijraah/web/external commonjs \"next/dist/compiled/next-server/app-page.runtime.prod.js\"","webpack://@hijraah/web/external commonjs2 \"punycode\"","webpack://@hijraah/web/external commonjs2 \"assert\"","webpack://@hijraah/web/external commonjs \"next/dist/server/app-render/action-async-storage.external.js\"","webpack://@hijraah/web/external commonjs2 \"process\"","webpack://@hijraah/web/external commonjs2 \"os\"","webpack://@hijraah/web/external commonjs2 \"stream\"","webpack://@hijraah/web/external commonjs2 \"util\"","webpack://@hijraah/web/external commonjs2 \"fs\"","webpack://@hijraah/web/external commonjs \"next/dist/server/app-render/work-async-storage.external.js\"","webpack://@hijraah/web/external node-commonjs \"node:child_process\"","webpack://@hijraah/web/external commonjs2 \"path\"","webpack://@hijraah/web/external commonjs2 \"tls\"","webpack://@hijraah/web/external commonjs2 \"diagnostics_channel\"","webpack://@hijraah/web/external node-commonjs \"node:http\"","webpack://@hijraah/web/external node-commonjs \"node:stream/web\"","webpack://@hijraah/web/external node-commonjs \"node:zlib\"","webpack://@hijraah/web/external node-commonjs \"node:tls\"","webpack://@hijraah/web/external node-commonjs \"node:https\"","webpack://@hijraah/web/external commonjs \"next/dist/compiled/next-server/app-route.runtime.prod.js\"","webpack://@hijraah/web/external node-commonjs \"node:os\"","webpack://@hijraah/web/external node-commonjs \"node:diagnostics_channel\"","webpack://@hijraah/web/external commonjs2 \"crypto\"","webpack://@hijraah/web/external commonjs2 \"https\"","webpack://@hijraah/web/external node-commonjs \"node:stream\"","webpack://@hijraah/web/external node-commonjs \"node:util\"","webpack://@hijraah/web/../../packages/database/src/client.ts","webpack://@hijraah/web/external commonjs \"next/dist/server/app-render/work-unit-async-storage.external.js\"","webpack://@hijraah/web/external node-commonjs \"node:fs\"","webpack://@hijraah/web/external commonjs2 \"worker_threads\"","webpack://@hijraah/web/external commonjs2 \"zlib\"","webpack://@hijraah/web/external commonjs2 \"perf_hooks\"","webpack://@hijraah/web/external node-commonjs \"node:worker_threads\"","webpack://@hijraah/web/external node-commonjs \"node:path\"","webpack://@hijraah/web/external node-commonjs \"node:net\"","webpack://@hijraah/web/external commonjs2 \"buffer\"","webpack://@hijraah/web/external commonjs2 \"url\"","webpack://@hijraah/web/external commonjs2 \"child_process\"","webpack://@hijraah/web/external node-commonjs \"node:readline\"","webpack://@hijraah/web/external commonjs2 \"http\"","webpack://@hijraah/web/external commonjs2 \"tty\"","webpack://@hijraah/web/external commonjs2 \"async_hooks\"","webpack://@hijraah/web/external node-commonjs \"node:inspector\"","webpack://@hijraah/web/external commonjs2 \"net\"","webpack://@hijraah/web/external commonjs2 \"events\""],"sourcesContent":["module.exports = require(\"next/dist/server/app-render/after-task-async-storage.external.js\");","import OpenAI from \"openai\";\r\n\r\nconst openai = new OpenAI({\r\n  apiKey: process.env.OPENAI_API_KEY!,\r\n});\r\n\r\n/**\r\n * Generate embeddings using OpenAI's text-embedding-3-small model\r\n */\r\nexport async function generateEmbedding(text: string): Promise<number[]> {\r\n  try {\r\n    const response = await openai.embeddings.create({\r\n      model: \"text-embedding-3-small\",\r\n      input: text.trim(),\r\n      encoding_format: \"float\",\r\n    });\r\n\r\n    if (!response.data || response.data.length === 0) {\r\n      throw new Error(\"No embedding data returned\");\r\n    }\r\n\r\n    return response.data[0].embedding;\r\n  } catch (error) {\r\n    console.error(\"Error generating embedding:\", error);\r\n    throw new Error(`Failed to generate embedding: ${error}`);\r\n  }\r\n}\r\n\r\n/**\r\n * Generate embeddings in batches for multiple texts\r\n */\r\nexport async function generateEmbeddings(texts: string[]): Promise<number[][]> {\r\n  try {\r\n    const response = await openai.embeddings.create({\r\n      model: \"text-embedding-3-small\",\r\n      input: texts.map((text) => text.trim()),\r\n      encoding_format: \"float\",\r\n    });\r\n\r\n    if (!response.data || response.data.length !== texts.length) {\r\n      throw new Error(\"Embedding count mismatch\");\r\n    }\r\n\r\n    return response.data.map((item) => item.embedding);\r\n  } catch (error) {\r\n    console.error(\"Error generating embeddings:\", error);\r\n    throw new Error(`Failed to generate embeddings: ${error}`);\r\n  }\r\n}\r\n\r\n/**\r\n * Calculate cosine similarity between two embeddings\r\n */\r\nexport function cosineSimilarity(a: number[], b: number[]): number {\r\n  if (a.length !== b.length) {\r\n    throw new Error(\"Embedding dimensions must match\");\r\n  }\r\n\r\n  let dotProduct = 0;\r\n  let normA = 0;\r\n  let normB = 0;\r\n\r\n  for (let i = 0; i < a.length; i++) {\r\n    dotProduct += a[i] * b[i];\r\n    normA += a[i] * a[i];\r\n    normB += b[i] * b[i];\r\n  }\r\n\r\n  return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));\r\n}\r\n","import FirecrawlApp from \"@mendable/firecrawl-js\";\r\nimport { db } from \"@hijraah/database/client\";\r\nimport {\r\n  webIndexes,\r\n  crawlJobs,\r\n  documents,\r\n  documentChunks,\r\n} from \"@hijraah/database/schema\";\r\nimport { eq } from \"drizzle-orm\";\r\nimport { generateEmbedding } from \"@/lib/ai/embeddings\";\r\nimport type { CrawlJobUpdate, FirecrawlJobResponse } from \"@hijraah/types\";\r\n\r\n// Initialize Firecrawl client\r\nconst firecrawl = new FirecrawlApp({\r\n  apiKey: process.env.FIRECRAWL_API_KEY!,\r\n});\r\n\r\nexport class FirecrawlService {\r\n  /**\r\n   * Start a crawl job for a web index\r\n   */\r\n  static async startCrawl(webIndexId: string): Promise<{ jobId: string }> {\r\n    try {\r\n      // Get web index details\r\n      const [webIndex] = await db\r\n        .select()\r\n        .from(webIndexes)\r\n        .where(eq(webIndexes.id, webIndexId))\r\n        .limit(1);\r\n\r\n      if (!webIndex) {\r\n        throw new Error(\"Web index not found\");\r\n      }\r\n\r\n      const crawlConfig = (webIndex.crawlConfig as any) || {};\r\n\r\n      // Start Firecrawl job\r\n      const crawlResponse = await firecrawl.crawlUrl(webIndex.url, {\r\n        maxPages: crawlConfig.maxPages || 100,\r\n        includeHtml: false,\r\n        includeMarkdown: true,\r\n        includeMetadata: true,\r\n        excludePaths: crawlConfig.excludePatterns || [],\r\n        includePaths: crawlConfig.includePatterns || [],\r\n        respectRobotsTxt: crawlConfig.respectRobotsTxt !== false,\r\n        delay: crawlConfig.delay || 1000,\r\n        extractorOptions: {\r\n          mode: \"llm-extraction\",\r\n          extractionPrompt:\r\n            \"Extract the main content and metadata from this page, focusing on text content that would be useful for search and question-answering.\",\r\n        },\r\n      });\r\n\r\n      if (!crawlResponse.success) {\r\n        throw new Error(`Firecrawl job failed: ${crawlResponse.error}`);\r\n      }\r\n\r\n      const jobId = crawlResponse.id || crawlResponse.jobId;\r\n\r\n      // Update crawl job record\r\n      await db\r\n        .update(crawlJobs)\r\n        .set({\r\n          firecrawlJobId: jobId,\r\n          status: \"processing\",\r\n          startedAt: new Date(),\r\n        })\r\n        .where(eq(crawlJobs.webIndexId, webIndexId));\r\n\r\n      return { jobId };\r\n    } catch (error) {\r\n      console.error(\"Error starting crawl:\", error);\r\n      throw error;\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Check the status of a running crawl job\r\n   */\r\n  static async checkCrawlStatus(\r\n    firecrawlJobId: string\r\n  ): Promise<CrawlJobUpdate> {\r\n    try {\r\n      const statusResponse = await firecrawl.checkCrawlStatus(firecrawlJobId);\r\n\r\n      if (!statusResponse.success) {\r\n        throw new Error(`Failed to check status: ${statusResponse.error}`);\r\n      }\r\n\r\n      const status = statusResponse.status;\r\n      const isCompleted = status === \"completed\";\r\n      const isFailed = status === \"failed\";\r\n\r\n      return {\r\n        status: isFailed ? \"failed\" : isCompleted ? \"completed\" : \"processing\",\r\n        pagesProcessed: statusResponse.current || 0,\r\n        totalPages: statusResponse.total,\r\n        data: isCompleted ? statusResponse.data : undefined,\r\n        errorMessage: isFailed ? statusResponse.error : undefined,\r\n      };\r\n    } catch (error) {\r\n      console.error(\"Error checking crawl status:\", error);\r\n      return {\r\n        status: \"failed\",\r\n        errorMessage: error instanceof Error ? error.message : \"Unknown error\",\r\n        pagesProcessed: 0,\r\n      };\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Process completed crawl results and store in database\r\n   */\r\n  static async processCrawlResults(\r\n    webIndexId: string,\r\n    crawlData: any[]\r\n  ): Promise<void> {\r\n    try {\r\n      const [webIndex] = await db\r\n        .select()\r\n        .from(webIndexes)\r\n        .where(eq(webIndexes.id, webIndexId))\r\n        .limit(1);\r\n\r\n      if (!webIndex) {\r\n        throw new Error(\"Web index not found\");\r\n      }\r\n\r\n      console.log(\r\n        `Processing ${crawlData.length} pages for web index ${webIndexId}`\r\n      );\r\n\r\n      // Process each crawled page\r\n      for (const page of crawlData) {\r\n        if (!page.markdown || !page.metadata?.title) {\r\n          continue; // Skip pages without content\r\n        }\r\n\r\n        // Create document record\r\n        const [document] = await db\r\n          .insert(documents)\r\n          .values({\r\n            userId: webIndex.userId,\r\n            webIndexId: webIndexId,\r\n            filename:\r\n              page.metadata.title ||\r\n              new URL(page.metadata.sourceURL || page.url).pathname,\r\n            filePath: page.metadata.sourceURL || page.url,\r\n            fileType: \"text/html\",\r\n            fileSize: page.markdown.length,\r\n            title: page.metadata.title || \"Untitled\",\r\n            content: page.markdown,\r\n            status: \"processing\",\r\n            metadata: {\r\n              url: page.metadata.sourceURL || page.url,\r\n              description: page.metadata.description,\r\n              keywords: page.metadata.keywords,\r\n              ogTitle: page.metadata.ogTitle,\r\n              ogDescription: page.metadata.ogDescription,\r\n              statusCode: page.metadata.statusCode,\r\n              crawledAt: new Date().toISOString(),\r\n            },\r\n          })\r\n          .returning();\r\n\r\n        // Create embeddings for the content\r\n        await this.createDocumentEmbeddings(document.id, page.markdown);\r\n\r\n        // Update document status\r\n        await db\r\n          .update(documents)\r\n          .set({ status: \"complete\" })\r\n          .where(eq(documents.id, document.id));\r\n      }\r\n\r\n      // Update web index statistics\r\n      await db\r\n        .update(webIndexes)\r\n        .set({\r\n          pagesCrawled: crawlData.length,\r\n          totalPages: crawlData.length,\r\n          lastCrawledAt: new Date(),\r\n          updatedAt: new Date(),\r\n        })\r\n        .where(eq(webIndexes.id, webIndexId));\r\n\r\n      console.log(\r\n        `Completed processing ${crawlData.length} pages for web index ${webIndexId}`\r\n      );\r\n    } catch (error) {\r\n      console.error(\"Error processing crawl results:\", error);\r\n      throw error;\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Create embeddings for document content\r\n   */\r\n  private static async createDocumentEmbeddings(\r\n    documentId: string,\r\n    content: string\r\n  ): Promise<void> {\r\n    try {\r\n      // Split content into chunks (simple approach - can be enhanced)\r\n      const chunks = this.splitIntoChunks(content, 1000, 200); // 1000 chars with 200 char overlap\r\n\r\n      for (let i = 0; i < chunks.length; i++) {\r\n        const chunk = chunks[i];\r\n\r\n        // Generate embedding for the chunk\r\n        const embedding = await generateEmbedding(chunk);\r\n\r\n        // Store chunk with embedding\r\n        await db.insert(documentChunks).values({\r\n          documentId: documentId,\r\n          chunkIndex: i,\r\n          textContent: chunk,\r\n          embedding: embedding,\r\n          tokenCount: Math.ceil(chunk.length / 4), // Rough estimate\r\n        });\r\n      }\r\n    } catch (error) {\r\n      console.error(\"Error creating document embeddings:\", error);\r\n      throw error;\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Split text into overlapping chunks\r\n   */\r\n  private static splitIntoChunks(\r\n    text: string,\r\n    chunkSize: number = 1000,\r\n    overlap: number = 200\r\n  ): string[] {\r\n    const chunks: string[] = [];\r\n    let start = 0;\r\n\r\n    while (start < text.length) {\r\n      const end = Math.min(start + chunkSize, text.length);\r\n      const chunk = text.slice(start, end);\r\n\r\n      chunks.push(chunk);\r\n\r\n      if (end === text.length) break;\r\n      start += chunkSize - overlap;\r\n    }\r\n\r\n    return chunks;\r\n  }\r\n\r\n  /**\r\n   * Monitor and update all active crawl jobs\r\n   */\r\n  static async monitorActiveCrawls(): Promise<void> {\r\n    try {\r\n      // Get all processing crawl jobs\r\n      const activeCrawls = await db\r\n        .select({\r\n          id: crawlJobs.id,\r\n          webIndexId: crawlJobs.webIndexId,\r\n          firecrawlJobId: crawlJobs.firecrawlJobId,\r\n        })\r\n        .from(crawlJobs)\r\n        .where(eq(crawlJobs.status, \"processing\"));\r\n\r\n      console.log(`Monitoring ${activeCrawls.length} active crawl jobs`);\r\n\r\n      for (const crawl of activeCrawls) {\r\n        if (!crawl.firecrawlJobId) continue;\r\n\r\n        try {\r\n          const statusUpdate = await this.checkCrawlStatus(\r\n            crawl.firecrawlJobId\r\n          );\r\n\r\n          // Update crawl job status\r\n          await db\r\n            .update(crawlJobs)\r\n            .set({\r\n              status: statusUpdate.status,\r\n              pagesProcessed: statusUpdate.pagesProcessed,\r\n              errorMessage: statusUpdate.errorMessage,\r\n              completedAt:\r\n                statusUpdate.status === \"completed\" ||\r\n                statusUpdate.status === \"failed\"\r\n                  ? new Date()\r\n                  : undefined,\r\n              metadata: {\r\n                ...crawl,\r\n                lastStatusCheck: new Date().toISOString(),\r\n                totalPages: statusUpdate.totalPages,\r\n              },\r\n            })\r\n            .where(eq(crawlJobs.id, crawl.id));\r\n\r\n          // Process results if completed\r\n          if (statusUpdate.status === \"completed\" && statusUpdate.data) {\r\n            await this.processCrawlResults(crawl.webIndexId, statusUpdate.data);\r\n          }\r\n        } catch (error) {\r\n          console.error(`Error monitoring crawl ${crawl.id}:`, error);\r\n\r\n          // Mark as failed\r\n          await db\r\n            .update(crawlJobs)\r\n            .set({\r\n              status: \"failed\",\r\n              errorMessage:\r\n                error instanceof Error ? error.message : \"Monitoring failed\",\r\n              completedAt: new Date(),\r\n            })\r\n            .where(eq(crawlJobs.id, crawl.id));\r\n        }\r\n      }\r\n    } catch (error) {\r\n      console.error(\"Error monitoring active crawls:\", error);\r\n    }\r\n  }\r\n}\r\n\r\nexport default FirecrawlService;\r\n","import { NextRequest, NextResponse } from \"next/server\";\r\nimport { auth } from \"@/lib/auth\";\r\nimport FirecrawlService from \"@/lib/services/firecrawl\";\r\n\r\n// This endpoint should be called by a background job scheduler (like Vercel Cron or external service)\r\nexport async function POST(request: NextRequest) {\r\n  try {\r\n    // Verify admin access or use API key authentication\r\n    const authHeader = request.headers.get(\"authorization\");\r\n    const expectedApiKey = process.env.CRON_SECRET || process.env.ADMIN_API_KEY;\r\n\r\n    if (!authHeader || !expectedApiKey) {\r\n      return NextResponse.json({ error: \"Unauthorized\" }, { status: 401 });\r\n    }\r\n\r\n    const token = authHeader.replace(\"Bearer \", \"\");\r\n    if (token !== expectedApiKey) {\r\n      return NextResponse.json({ error: \"Invalid API key\" }, { status: 401 });\r\n    }\r\n\r\n    console.log(\"ðŸ” Starting crawl monitoring job\");\r\n\r\n    // Monitor all active crawls\r\n    await FirecrawlService.monitorActiveCrawls();\r\n\r\n    return NextResponse.json({\r\n      success: true,\r\n      message: \"Crawl monitoring completed\",\r\n      timestamp: new Date().toISOString(),\r\n    });\r\n  } catch (error) {\r\n    console.error(\"Error in crawl monitoring:\", error);\r\n    return NextResponse.json(\r\n      {\r\n        error: \"Monitoring failed\",\r\n        details: error instanceof Error ? error.message : \"Unknown error\",\r\n      },\r\n      { status: 500 }\r\n    );\r\n  }\r\n}\r\n\r\n// GET endpoint for manual monitoring trigger (admin only)\r\nexport async function GET(request: NextRequest) {\r\n  try {\r\n    const session = await auth();\r\n    if (!session?.user?.id) {\r\n      return NextResponse.json({ error: \"Unauthorized\" }, { status: 401 });\r\n    }\r\n\r\n    // Check if user is admin (you'll need to implement this check)\r\n    // For now, we'll just check if they have access to monitoring\r\n    console.log(\"ðŸ” Manual crawl monitoring triggered by admin\");\r\n\r\n    await FirecrawlService.monitorActiveCrawls();\r\n\r\n    return NextResponse.json({\r\n      success: true,\r\n      message: \"Manual crawl monitoring completed\",\r\n      triggeredBy: session.user.id,\r\n      timestamp: new Date().toISOString(),\r\n    });\r\n  } catch (error) {\r\n    console.error(\"Error in manual crawl monitoring:\", error);\r\n    return NextResponse.json(\r\n      {\r\n        error: \"Manual monitoring failed\",\r\n        details: error instanceof Error ? error.message : \"Unknown error\",\r\n      },\r\n      { status: 500 }\r\n    );\r\n  }\r\n}\r\n","import * as origModule from 'next/dist/server/app-render/work-unit-async-storage.external.js';\nimport * as serverComponentModule from '__SENTRY_WRAPPING_TARGET_FILE__.cjs';\nexport * from '__SENTRY_WRAPPING_TARGET_FILE__.cjs';\nexport {} from '__SENTRY_WRAPPING_TARGET_FILE__.cjs';\nimport * as Sentry from '@sentry/nextjs';\n\n// @ts-expect-error Because we cannot be sure if the RequestAsyncStorage module exists (it is not part of the Next.js public\n// API) we use a shim if it doesn't exist. The logic for this is in the wrapping loader.\n\nconst asyncStorageModule = { ...origModule } ;\n\nconst requestAsyncStorage =\n  'workUnitAsyncStorage' in asyncStorageModule\n    ? asyncStorageModule.workUnitAsyncStorage\n    : 'requestAsyncStorage' in asyncStorageModule\n      ? asyncStorageModule.requestAsyncStorage\n      : undefined;\n\nfunction wrapHandler(handler, method) {\n  // Running the instrumentation code during the build phase will mark any function as \"dynamic\" because we're accessing\n  // the Request object. We do not want to turn handlers dynamic so we skip instrumentation in the build phase.\n  if (process.env.NEXT_PHASE === 'phase-production-build') {\n    return handler;\n  }\n\n  if (typeof handler !== 'function') {\n    return handler;\n  }\n\n  return new Proxy(handler, {\n    apply: (originalFunction, thisArg, args) => {\n      let headers = undefined;\n\n      // We try-catch here just in case the API around `requestAsyncStorage` changes unexpectedly since it is not public API\n      try {\n        const requestAsyncStore = requestAsyncStorage?.getStore() ;\n        headers = requestAsyncStore?.headers;\n      } catch (e) {\n        /** empty */\n      }\n\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      return Sentry.wrapRouteHandlerWithSentry(originalFunction , {\n        method,\n        parameterizedRoute: '/api/admin/monitor-crawls',\n        headers,\n      }).apply(thisArg, args);\n    },\n  });\n}\n\n// eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\nconst GET = wrapHandler(serverComponentModule.GET , 'GET');\n// eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\nconst POST = wrapHandler(serverComponentModule.POST , 'POST');\n// eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\nconst PUT = wrapHandler(serverComponentModule.PUT , 'PUT');\n// eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\nconst PATCH = wrapHandler(serverComponentModule.PATCH , 'PATCH');\n// eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\nconst DELETE = wrapHandler(serverComponentModule.DELETE , 'DELETE');\n// eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\nconst HEAD = wrapHandler(serverComponentModule.HEAD , 'HEAD');\n// eslint-disable-next-line @typescript-eslint/no-unsafe-member-access\nconst OPTIONS = wrapHandler(serverComponentModule.OPTIONS , 'OPTIONS');\n\nexport { DELETE, GET, HEAD, OPTIONS, PATCH, POST, PUT };\n","import { AppRouteRouteModule } from \"next/dist/server/route-modules/app-route/module.compiled\";\nimport { RouteKind } from \"next/dist/server/route-kind\";\nimport { patchFetch as _patchFetch } from \"next/dist/server/lib/patch-fetch\";\nimport * as userland from \"E:\\\\downloads\\\\Hijraah\\\\apps\\\\web\\\\src\\\\app\\\\api\\\\admin\\\\monitor-crawls\\\\route.ts\";\n// We inject the nextConfigOutput here so that we can use them in the route\n// module.\nconst nextConfigOutput = \"\"\nconst routeModule = new AppRouteRouteModule({\n    definition: {\n        kind: RouteKind.APP_ROUTE,\n        page: \"/api/admin/monitor-crawls/route\",\n        pathname: \"/api/admin/monitor-crawls\",\n        filename: \"route\",\n        bundlePath: \"app/api/admin/monitor-crawls/route\"\n    },\n    resolvedPagePath: \"E:\\\\downloads\\\\Hijraah\\\\apps\\\\web\\\\src\\\\app\\\\api\\\\admin\\\\monitor-crawls\\\\route.ts\",\n    nextConfigOutput,\n    userland\n});\n// Pull out the exports that we need to expose from the module. This should\n// be eliminated when we've moved the other routes to the new format. These\n// are used to hook into the route.\nconst { workAsyncStorage, workUnitAsyncStorage, serverHooks } = routeModule;\nfunction patchFetch() {\n    return _patchFetch({\n        workAsyncStorage,\n        workUnitAsyncStorage\n    });\n}\nexport { routeModule, workAsyncStorage, workUnitAsyncStorage, serverHooks, patchFetch,  };\n\n//# sourceMappingURL=app-route.js.map","module.exports = require(\"module\");","module.exports = require(\"next/dist/compiled/next-server/app-page.runtime.prod.js\");","module.exports = require(\"punycode\");","module.exports = require(\"assert\");","module.exports = require(\"next/dist/server/app-render/action-async-storage.external.js\");","module.exports = require(\"process\");","module.exports = require(\"os\");","module.exports = require(\"stream\");","module.exports = require(\"util\");","module.exports = require(\"fs\");","module.exports = require(\"next/dist/server/app-render/work-async-storage.external.js\");","module.exports = require(\"node:child_process\");","module.exports = require(\"path\");","module.exports = require(\"tls\");","module.exports = require(\"diagnostics_channel\");","module.exports = require(\"node:http\");","module.exports = require(\"node:stream/web\");","module.exports = require(\"node:zlib\");","module.exports = require(\"node:tls\");","module.exports = require(\"node:https\");","module.exports = require(\"next/dist/compiled/next-server/app-route.runtime.prod.js\");","module.exports = require(\"node:os\");","module.exports = require(\"node:diagnostics_channel\");","module.exports = require(\"crypto\");","module.exports = require(\"https\");","module.exports = require(\"node:stream\");","module.exports = require(\"node:util\");","import { drizzle } from \"drizzle-orm/postgres-js\";\r\nimport postgres from \"postgres\";\r\nimport * as schema from \"./schema\";\r\n\r\n// Environment variable setup\r\nconst connectionString = process.env.DATABASE_URL;\r\n\r\nif (!connectionString) {\r\n  throw new Error(\"DATABASE_URL environment variable is required\");\r\n}\r\n\r\n// Create the connection\r\nconst client = postgres(connectionString, {\r\n  max: 10,\r\n  idle_timeout: 20,\r\n  connect_timeout: 10,\r\n});\r\n\r\n// Create the Drizzle database instance\r\nexport const db = drizzle(client, {\r\n  schema,\r\n  logger: process.env.NODE_ENV === \"development\",\r\n});\r\n\r\n// Export types for use in applications\r\nexport type Database = typeof db;\r\n\r\n// Export the client for manual queries if needed\r\nexport { client as pgClient };\r\n\r\n// Export all schemas\r\nexport * from \"./schema\";\r\n","module.exports = require(\"next/dist/server/app-render/work-unit-async-storage.external.js\");","module.exports = require(\"node:fs\");","module.exports = require(\"worker_threads\");","module.exports = require(\"zlib\");","module.exports = require(\"perf_hooks\");","module.exports = require(\"node:worker_threads\");","module.exports = require(\"node:path\");","module.exports = require(\"node:net\");","module.exports = require(\"buffer\");","module.exports = require(\"url\");","module.exports = require(\"child_process\");","module.exports = require(\"node:readline\");","module.exports = require(\"http\");","module.exports = require(\"tty\");","module.exports = require(\"async_hooks\");","module.exports = require(\"node:inspector\");","module.exports = require(\"net\");","module.exports = require(\"events\");"],"names":["openai","OpenAI","apiKey","process","env","OPENAI_API_KEY","generateEmbedding","text","response","embeddings","create","model","input","trim","encoding_format","data","length","embedding","error","console","firecrawl","FirecrawlApp","FIRECRAWL_API_KEY","FirecrawlService","startCrawl","webIndexId","webIndex","db","select","from","webIndexes","where","eq","id","limit","crawlConfig","crawlResponse","crawlUrl","url","maxPages","includeHtml","includeMarkdown","includeMetadata","excludePaths","excludePatterns","includePaths","includePatterns","respectRobotsTxt","delay","extractorOptions","mode","extractionPrompt","success","jobId","update","crawlJobs","set","firecrawlJobId","status","startedAt","Date","checkCrawlStatus","statusResponse","Error","isCompleted","isFailed","pagesProcessed","current","totalPages","total","undefined","errorMessage","message","processCrawlResults","crawlData","page","markdown","metadata","title","document","insert","documents","values","userId","filename","URL","sourceURL","pathname","filePath","fileType","fileSize","content","description","keywords","ogTitle","ogDescription","statusCode","crawledAt","toISOString","returning","createDocumentEmbeddings","pagesCrawled","lastCrawledAt","updatedAt","documentId","chunks","splitIntoChunks","i","chunk","documentChunks","chunkIndex","textContent","tokenCount","Math","ceil","chunkSize","overlap","start","end","min","slice","push","monitorActiveCrawls","crawl","activeCrawls","statusUpdate","completedAt","lastStatusCheck","POST","request","authHeader","headers","get","expectedApiKey","ADMIN_API_KEY","NextResponse","json","replace","timestamp","details","GET","session","auth","user","triggeredBy","serverComponentModule.GET","serverComponentModule.POST","serverComponentModule.PUT","serverComponentModule.PATCH","serverComponentModule.DELETE","serverComponentModule.HEAD","serverComponentModule.OPTIONS","connectionString","DATABASE_URL","client","postgres","max","idle_timeout","connect_timeout","drizzle","schema","logger"],"sourceRoot":""}